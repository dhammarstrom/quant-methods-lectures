[
  {
    "objectID": "01-ds-intro.html#data-is-everywhere",
    "href": "01-ds-intro.html#data-is-everywhere",
    "title": "Introduction to data science",
    "section": "Data is everywhere",
    "text": "Data is everywhere"
  },
  {
    "objectID": "01-ds-intro.html#the-ppdac-cycle",
    "href": "01-ds-intro.html#the-ppdac-cycle",
    "title": "Introduction to data science",
    "section": "The PPDAC cycle1",
    "text": "The PPDAC cycle1\n\n\n\nA general approach to data-driven problem-solving\nData literacy and data science as opposed to statistics\n\n\n\n\n\n(Spiegelhalter 2019)"
  },
  {
    "objectID": "01-ds-intro.html#replication-and-reproducibility",
    "href": "01-ds-intro.html#replication-and-reproducibility",
    "title": "Introduction to data science",
    "section": "Replication and Reproducibility",
    "text": "Replication and Reproducibility\nA fully reproducible1 study has\n\nAvailable data.\nComputer code (software) that produces the results of the study.\nDocumentation that describes the software and data used in the study, and\nways to share the data and code.\n\n(Peng, Dominici, and Zeger 2006)"
  },
  {
    "objectID": "01-ds-intro.html#reproducibility-and-transparency-outside-science",
    "href": "01-ds-intro.html#reproducibility-and-transparency-outside-science",
    "title": "Introduction to data science",
    "section": "Reproducibility and transparency outside science",
    "text": "Reproducibility and transparency outside science\n\nData are valuable and often hard to get\nData may guide good decision-making, if understood\nEfficient management and use of data requires data literacy and data science skills"
  },
  {
    "objectID": "01-ds-intro.html#tools-in-data-science",
    "href": "01-ds-intro.html#tools-in-data-science",
    "title": "Introduction to data science",
    "section": "Tools in data science",
    "text": "Tools in data science\nWe want software where analyses can be:\n\nHuman- and computer-readable, meaning that we want to be able to write scripts or computer programs that execute the analyses.\nDocumented, meaning that along the code, we want to be able to describe what the code does.\nAvailable and able to share with others, meaning that our analyses can be run on open and free software to maximize the ability to share them.\n\n\n\nHuman- and computer-readable, meaning that we want to be able to write scripts, or computer programs that execute the analyses.\nDocumented, meaning that along the code we want to be able to describe what the code does.\nAvailable and able to share with other, meaning that we analyses can be run on open and free software to maximize ability to share them."
  },
  {
    "objectID": "01-ds-intro.html#tools-in-data-science-1",
    "href": "01-ds-intro.html#tools-in-data-science-1",
    "title": "Introduction to data science",
    "section": "Tools in data science",
    "text": "Tools in data science\n\nR and RStudio\nQuarto\nGit and GitHub"
  },
  {
    "objectID": "01-ds-intro.html#tools-in-data-science-2",
    "href": "01-ds-intro.html#tools-in-data-science-2",
    "title": "Introduction to data science",
    "section": "Tools in data science 1",
    "text": "Tools in data science 1\n\n(Wickham and Grolemund 2017)"
  },
  {
    "objectID": "01-ds-intro.html#how-to-learn-how-to-code",
    "href": "01-ds-intro.html#how-to-learn-how-to-code",
    "title": "Introduction to data science",
    "section": "How to learn how to code",
    "text": "How to learn how to code\n\nThere are (almost always) multiple solutions to a problem.\nSomeone else has already had the same problem\nFind your motivation\n“Microdosing”\n\n\n\nThere are (almost always) multiple solutions to a problem. When faced with difficulties, do not give up trying to search for a perfect single solution. Instead know that there are multiple ways of defining the problem and therefore multiple ways of making stuff work.\nSomeone else has already had the same problem. The internet is full of questions and answers, also related to what ever problem you might have. Learning how to write “googleable” questions is a great skill. By adding “in R” to your problem in a google search term often helps finding R related solutions.\nFind your motivation. The skills that you will learn in this course are transferable to countless potential work related roles for the future you! To be able to showcase these skills may lead you to your dream job! Find your motivation for learning how to analyze data and communicating insights!\n“Microdosing” statistical learning. Replace your social media influencers with R users and data scientists! I find R people on Twitter and mastodon. Tweets and posts in this format keeps your R brain going!"
  },
  {
    "objectID": "01-ds-intro.html#data-in-practice---storing-data-for-everyday-use",
    "href": "01-ds-intro.html#data-in-practice---storing-data-for-everyday-use",
    "title": "Introduction to data science",
    "section": "Data in practice - Storing data for everyday use",
    "text": "Data in practice - Storing data for everyday use\n\nSpreadsheets can be used for efficient storage of data for everyday use\nSpreadsheet software contains functions that adds information on top of the data…"
  },
  {
    "objectID": "01-ds-intro.html#section-1",
    "href": "01-ds-intro.html#section-1",
    "title": "Introduction to data science",
    "section": "",
    "text": "All happy families are alike; each unhappy family is unhappy in its own way."
  },
  {
    "objectID": "01-ds-intro.html#data-organization-in-spreadsheets-empty-cells",
    "href": "01-ds-intro.html#data-organization-in-spreadsheets-empty-cells",
    "title": "Introduction to data science",
    "section": "Data Organization in Spreadsheets: Empty cells1",
    "text": "Data Organization in Spreadsheets: Empty cells1\n\n(Broman and Woo 2018)"
  },
  {
    "objectID": "01-ds-intro.html#data-organization-in-spreadsheets-a-tidy-version-happy-family",
    "href": "01-ds-intro.html#data-organization-in-spreadsheets-a-tidy-version-happy-family",
    "title": "Introduction to data science",
    "section": "Data Organization in Spreadsheets: A tidy version (happy family)",
    "text": "Data Organization in Spreadsheets: A tidy version (happy family)"
  },
  {
    "objectID": "01-ds-intro.html#data-organization-in-spreadsheets-nonrectangular-layouts",
    "href": "01-ds-intro.html#data-organization-in-spreadsheets-nonrectangular-layouts",
    "title": "Introduction to data science",
    "section": "Data Organization in Spreadsheets: Nonrectangular layouts",
    "text": "Data Organization in Spreadsheets: Nonrectangular layouts"
  },
  {
    "objectID": "01-ds-intro.html#data-organization-in-spreadsheets-data-dictionary",
    "href": "01-ds-intro.html#data-organization-in-spreadsheets-data-dictionary",
    "title": "Introduction to data science",
    "section": "Data Organization in Spreadsheets: Data dictionary",
    "text": "Data Organization in Spreadsheets: Data dictionary"
  },
  {
    "objectID": "01-ds-intro.html#data-organization-in-spreadsheets-plain-text",
    "href": "01-ds-intro.html#data-organization-in-spreadsheets-plain-text",
    "title": "Introduction to data science",
    "section": "Data Organization in Spreadsheets: Plain text",
    "text": "Data Organization in Spreadsheets: Plain text"
  },
  {
    "objectID": "01-ds-intro.html#section-2",
    "href": "01-ds-intro.html#section-2",
    "title": "Introduction to data science",
    "section": "",
    "text": "Minimize the risk of failure by adopting good habits!\n\n\n\n\n\n\nFrom wikipedia: Maria Spelterini (1876) is walking across a tightrope across the Niagara Gorge, from the United States side to Canada, with her feet in peach baskets. In the background is the Niagara Suspension Bridge, which is full of spectators. In the distant background is the Niagara Falls.\nsource: https://commons.wikimedia.org/wiki/File:Maria_Spelterini_at_Suspension_Bridge.jpg#/media/File:Maria_Spelterini_at_Suspension_Bridge.jpg"
  },
  {
    "objectID": "01-ds-intro.html#references",
    "href": "01-ds-intro.html#references",
    "title": "Introduction to data science",
    "section": "References",
    "text": "References\n\n\n\n\n\n\nBroman, Karl W., and Kara H. Woo. 2018. “Data Organization in Spreadsheets.” Journal Article. The American Statistician 72 (1): 2–10. https://doi.org/10.1080/00031305.2017.1375989.\n\n\nPeng, R. D., F. Dominici, and S. L. Zeger. 2006. “Reproducible Epidemiologic Research.” Journal Article. Am J Epidemiol 163 (9): 783–89. https://doi.org/10.1093/aje/kwj093.\n\n\nSpiegelhalter, D. J. 2019. The Art of Statistics : How to Learn from Data. Book. First US edition. New York: Basic Books.\n\n\nWickham, Hadley, and Garrett Grolemund. 2017. R for Data Science: Import, Tidy, Transform, Visualize, and Model Data. 1st ed. Paperback; O’Reilly Media. http://r4ds.had.co.nz/."
  },
  {
    "objectID": "02-datavis-homework.html",
    "href": "02-datavis-homework.html",
    "title": "Homework - reproducing figures",
    "section": "",
    "text": "library(tidyverse)\n\n\n3\n\nGet an overview of the available variables\n\n\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.1     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nchild_heart &lt;- read_csv(\"https://raw.githubusercontent.com/dspiegel29/ArtofStatistics/master/01-1-2-3-child-heart-survival-times/01-1-child-heart-survival-x.csv\")\n\nRows: 13 Columns: 6\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): Hospital\ndbl (5): Operations, Survivors, Deaths, ThirtyDaySurvival, PercentageDying\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n3head(child_heart)\n\n# A tibble: 6 × 6\n  Hospital         Operations Survivors Deaths ThirtyDaySurvival PercentageDying\n  &lt;chr&gt;                 &lt;dbl&gt;     &lt;dbl&gt;  &lt;dbl&gt;             &lt;dbl&gt;           &lt;dbl&gt;\n1 London - Harley…        418       413      5              98.8             1.2\n2 Leicester               607       593     14              97.7             2.3\n3 Newcastle               668       653     15              97.8             2.2\n4 Glasgow                 760       733     27              96.3             3.7\n5 Southampton             829       815     14              98.3             1.7\n6 Bristol                 835       821     14              98.3             1.7"
  },
  {
    "objectID": "02-datavis-homework.html#first-steps",
    "href": "02-datavis-homework.html#first-steps",
    "title": "Homework - reproducing figures",
    "section": "",
    "text": "library(tidyverse)\n\n\n3\n\nGet an overview of the available variables\n\n\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.1     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nchild_heart &lt;- read_csv(\"https://raw.githubusercontent.com/dspiegel29/ArtofStatistics/master/01-1-2-3-child-heart-survival-times/01-1-child-heart-survival-x.csv\")\n\nRows: 13 Columns: 6\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): Hospital\ndbl (5): Operations, Survivors, Deaths, ThirtyDaySurvival, PercentageDying\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n3head(child_heart)\n\n# A tibble: 6 × 6\n  Hospital         Operations Survivors Deaths ThirtyDaySurvival PercentageDying\n  &lt;chr&gt;                 &lt;dbl&gt;     &lt;dbl&gt;  &lt;dbl&gt;             &lt;dbl&gt;           &lt;dbl&gt;\n1 London - Harley…        418       413      5              98.8             1.2\n2 Leicester               607       593     14              97.7             2.3\n3 Newcastle               668       653     15              97.8             2.2\n4 Glasgow                 760       733     27              96.3             3.7\n5 Southampton             829       815     14              98.3             1.7\n6 Bristol                 835       821     14              98.3             1.7"
  },
  {
    "objectID": "02-datavis-homework.html#what-should-be-the-end-result",
    "href": "02-datavis-homework.html#what-should-be-the-end-result",
    "title": "Homework - reproducing figures",
    "section": "What should be the end result?",
    "text": "What should be the end result?\n\n\n\n\n\nCalculate the proportion of operations to the total\nSort the variable hospital name based on proportion\nCreate a bar plot"
  },
  {
    "objectID": "02-datavis-homework.html#data-wrangling",
    "href": "02-datavis-homework.html#data-wrangling",
    "title": "Homework - reproducing figures",
    "section": "Data wrangling",
    "text": "Data wrangling\n\n1child_heart$percentage_op &lt;- 100 * (child_heart$Operations / sum(child_heart$Operations))\n2child_heart$Hospital &lt;- fct_reorder(child_heart$Hospital, child_heart$percentage_op)\n\nchild_heart$Hospital\n\n\n1\n\nCreating a new variable, operations per hospital expressed as a percentage of the total\n\n2\n\nOverwriting the existing variable Hospital with a factor variable\n\n\n\n\n [1] London - Harley Street       Leicester                   \n [3] Newcastle                    Glasgow                     \n [5] Southampton                  Bristol                     \n [7] Dublin                       Leeds                       \n [9] London - Brompton            Liverpool                   \n[11] London - Evelina             Birmingham                  \n[13] London - Great Ormond Street\n13 Levels: London - Harley Street Leicester Newcastle Glasgow ... London - Great Ormond Street"
  },
  {
    "objectID": "02-datavis-homework.html#data-wrangling-alternative",
    "href": "02-datavis-homework.html#data-wrangling-alternative",
    "title": "Homework - reproducing figures",
    "section": "Data wrangling alternative",
    "text": "Data wrangling alternative\n\nchild_heart &lt;- child_heart %&gt;%\n1        mutate(percentage_op = 100 * (Operations / sum(Operations)),\n2               Hospital = fct_reorder(Hospital, -percentage_op)) %&gt;%\n        print()\n\n\n1\n\nCreating a new variable, operations per hospital expressed as a percentage of the total\n\n2\n\nOverwriting the existing variable Hospital with a factor variable\n\n\n\n\n# A tibble: 13 × 7\n   Hospital        Operations Survivors Deaths ThirtyDaySurvival PercentageDying\n   &lt;fct&gt;                &lt;dbl&gt;     &lt;dbl&gt;  &lt;dbl&gt;             &lt;dbl&gt;           &lt;dbl&gt;\n 1 London - Harle…        418       413      5              98.8             1.2\n 2 Leicester              607       593     14              97.7             2.3\n 3 Newcastle              668       653     15              97.8             2.2\n 4 Glasgow                760       733     27              96.3             3.7\n 5 Southampton            829       815     14              98.3             1.7\n 6 Bristol                835       821     14              98.3             1.7\n 7 Dublin                 983       960     23              97.7             2.3\n 8 Leeds                 1038      1016     22              97.9             2.1\n 9 London - Bromp…       1094      1075     19              98.3             1.7\n10 Liverpool             1132      1112     20              98.2             1.8\n11 London - Eveli…       1220      1185     35              97.1             2.9\n12 Birmingham            1457      1421     36              97.5             2.5\n13 London - Great…       1892      1873     19              99               1  \n# ℹ 1 more variable: percentage_op &lt;dbl&gt;"
  },
  {
    "objectID": "02-datavis-homework.html#building-a-bar-plot",
    "href": "02-datavis-homework.html#building-a-bar-plot",
    "title": "Homework - reproducing figures",
    "section": "Building a bar plot",
    "text": "Building a bar plot\n\nggplot(data = child_heart, \n       aes(x = percentage_op, \n           y = Hospital)) + \n        geom_bar(stat = \"identity\")"
  },
  {
    "objectID": "02-datavis-homework.html#fixing-axis-labels",
    "href": "02-datavis-homework.html#fixing-axis-labels",
    "title": "Homework - reproducing figures",
    "section": "Fixing axis labels",
    "text": "Fixing axis labels\n\nggplot(data = child_heart, \n       aes(x = percentage_op, \n           y = Hospital)) + \n        geom_bar(stat = \"identity\") + \n        \n        labs(x = \"Percentage of all operations in 2012-15\\nthat are carried out in each hospital\") + \n        theme(axis.title.y = element_blank())"
  },
  {
    "objectID": "02-datavis-homework.html#fixing-axis-scales-x-axis",
    "href": "02-datavis-homework.html#fixing-axis-scales-x-axis",
    "title": "Homework - reproducing figures",
    "section": "Fixing axis scales (x-axis)",
    "text": "Fixing axis scales (x-axis)\n\nggplot(data = child_heart, \n       aes(x = percentage_op, \n           y = Hospital)) + \n        geom_bar(stat = \"identity\") + \n        \n        scale_x_continuous(limits = c(0, 16), \n                           breaks = c(0, 2, 4, 6, 8, 10, 12, 14, 16), \n                           expand = c(0, 0)) +\n        \n        \n        labs(x = \"Percentage of all operations in 2012-15\\nthat are carried out in each hospital\") + \n        theme(axis.title.y = element_blank())"
  },
  {
    "objectID": "02-datavis-homework.html#removing-reduntant-grid-lines-adding-plot-border-fixing-plot-background",
    "href": "02-datavis-homework.html#removing-reduntant-grid-lines-adding-plot-border-fixing-plot-background",
    "title": "Homework - reproducing figures",
    "section": "Removing reduntant grid lines, adding plot border, fixing plot background",
    "text": "Removing reduntant grid lines, adding plot border, fixing plot background\n\nggplot(data = child_heart, \n       aes(x = percentage_op, \n           y = Hospital)) + \n        geom_bar(stat = \"identity\") + \n        \n        scale_x_continuous(limits = c(0, 16), \n                           breaks = c(0, 2, 4, 6, 8, 10, 12, 14, 16), \n                           expand = c(0, 0)) +\n        \n        \n        labs(x = \"Percentage of all operations in 2012-15\\nthat are carried out in each hospital\") + \n        theme(axis.title.y = element_blank(), \n              panel.grid.major.y = element_blank(), \n              panel.grid.major.x = element_line(color = \"gray70\"), \n              panel.grid.minor.x = element_blank(), \n              panel.border = element_rect(color = \"black\", fill = NA), \n              panel.background = element_rect(fill = \"white\"))"
  },
  {
    "objectID": "02-datavis-homework.html#next-steps",
    "href": "02-datavis-homework.html#next-steps",
    "title": "Homework - reproducing figures",
    "section": "Next steps?",
    "text": "Next steps?"
  },
  {
    "objectID": "02-datavis.html#data-visualization",
    "href": "02-datavis.html#data-visualization",
    "title": "Data visualization",
    "section": "Data visualization",
    "text": "Data visualization\nWhy graphs?\n\n“… to help us perceive broad features of the data”\n“… to let us … see what else is there.”\n\n(Anscombe 1973)"
  },
  {
    "objectID": "02-datavis.html#four-data-sets---anscombes-quartet",
    "href": "02-datavis.html#four-data-sets---anscombes-quartet",
    "title": "Data visualization",
    "section": "Four data sets - Anscombe’s quartet",
    "text": "Four data sets - Anscombe’s quartet\n\n\n\n\nSummary statistics for Anscombe’s data\n\n\nDataset\nVariable\nMean\nSD\nMin\nMax\n\n\n\n\n1\nx\n9.0\n3.3\n4.0\n14.0\n\n\n2\nx\n9.0\n3.3\n4.0\n14.0\n\n\n3\nx\n9.0\n3.3\n4.0\n14.0\n\n\n4\nx\n9.0\n3.3\n8.0\n19.0\n\n\n1\ny\n7.5\n2.0\n4.3\n10.8\n\n\n2\ny\n7.5\n2.0\n3.1\n9.3\n\n\n3\ny\n7.5\n2.0\n5.4\n12.7\n\n\n4\ny\n7.5\n2.0\n5.2\n12.5\n\n\n\n\n\n\n(Anscombe 1973)"
  },
  {
    "objectID": "02-datavis.html#anscombes-quartet-2",
    "href": "02-datavis.html#anscombes-quartet-2",
    "title": "Data visualization",
    "section": "Anscombe’s quartet (2)",
    "text": "Anscombe’s quartet (2)\n\n\n\n\nRegression coeficients for for Anscombe’s data\n\n\nDataset\nIntercept\nSlope\nCorrelation\n\n\n\n\n1\n3\n0.5\n0.82\n\n\n2\n3\n0.5\n0.82\n\n\n3\n3\n0.5\n0.82\n\n\n4\n3\n0.5\n0.82\n\n\n\n\n\n\n(Anscombe 1973)"
  },
  {
    "objectID": "02-datavis.html#a-best-guess-of-the-data-pattern",
    "href": "02-datavis.html#a-best-guess-of-the-data-pattern",
    "title": "Data visualization",
    "section": "A best guess of the data pattern",
    "text": "A best guess of the data pattern"
  },
  {
    "objectID": "02-datavis.html#plotting-the-actual-data",
    "href": "02-datavis.html#plotting-the-actual-data",
    "title": "Data visualization",
    "section": "Plotting the actual data",
    "text": "Plotting the actual data"
  },
  {
    "objectID": "02-datavis.html#another-example---the-datasaurus",
    "href": "02-datavis.html#another-example---the-datasaurus",
    "title": "Data visualization",
    "section": "Another example - The Datasaurus",
    "text": "Another example - The Datasaurus\n\n\n\n\nThe Datasaurus datasets\n\n\nDataset\nMean x\nMean y\nSD x\nSD y\nCorrelation\n\n\n\n\naway\n54.27\n47.83\n16.77\n26.94\n-0.06\n\n\nbullseye\n54.27\n47.83\n16.77\n26.94\n-0.07\n\n\ncircle\n54.27\n47.84\n16.76\n26.93\n-0.07\n\n\ndino\n54.26\n47.83\n16.77\n26.94\n-0.06\n\n\ndots\n54.26\n47.84\n16.77\n26.93\n-0.06\n\n\nh_lines\n54.26\n47.83\n16.77\n26.94\n-0.06\n\n\nhigh_lines\n54.27\n47.84\n16.77\n26.94\n-0.07\n\n\nslant_down\n54.27\n47.84\n16.77\n26.94\n-0.07\n\n\nslant_up\n54.27\n47.83\n16.77\n26.94\n-0.07\n\n\nstar\n54.27\n47.84\n16.77\n26.93\n-0.06\n\n\nv_lines\n54.27\n47.84\n16.77\n26.94\n-0.07\n\n\nwide_lines\n54.27\n47.83\n16.77\n26.94\n-0.07\n\n\nx_shape\n54.26\n47.84\n16.77\n26.93\n-0.07"
  },
  {
    "objectID": "02-datavis.html#section",
    "href": "02-datavis.html#section",
    "title": "Data visualization",
    "section": "",
    "text": "Source: The datasauRus package"
  },
  {
    "objectID": "02-datavis.html#a-system-for-creating-graphs-in-r",
    "href": "02-datavis.html#a-system-for-creating-graphs-in-r",
    "title": "Data visualization",
    "section": "A system for creating graphs in R",
    "text": "A system for creating graphs in R\n\nThree layers of a graph, geometric objects, scales and coordinates and annotations of the plot(Wickham 2010)"
  },
  {
    "objectID": "02-datavis.html#a-system-for-creating-graphs",
    "href": "02-datavis.html#a-system-for-creating-graphs",
    "title": "Data visualization",
    "section": "A system for creating graphs",
    "text": "A system for creating graphs\n\nThree layers of a graph put together, geometric objects, scales and coordinates and annotations of the plot(Wickham 2010)"
  },
  {
    "objectID": "02-datavis.html#ggplot2---grammar-of-graphics",
    "href": "02-datavis.html#ggplot2---grammar-of-graphics",
    "title": "Data visualization",
    "section": "ggplot2 - Grammar of graphics",
    "text": "ggplot2 - Grammar of graphics\n\ndata → The dataset containing variables to plot\naesthetics → Scales where the data are mapped\ngeometries → Geometric representations of the data\nfacet → A part of the dataset\nstatistical transformations → Summaries of data\ncoordinates → The coordinate space\nthemes → Plot components not linked to data"
  },
  {
    "objectID": "02-datavis.html#creating-a-plot",
    "href": "02-datavis.html#creating-a-plot",
    "title": "Data visualization",
    "section": "Creating a plot",
    "text": "Creating a plot\n\n\n\n\nlibrary(\"palmerpenguins\")\n\ndata(\"penguins\")\n\npenguins %&gt;%\n        ggplot(aes(x = flipper_length_mm, \n                   y = body_mass_g)) + \n        geom_point()"
  },
  {
    "objectID": "02-datavis.html#mapping-many-variables",
    "href": "02-datavis.html#mapping-many-variables",
    "title": "Data visualization",
    "section": "Mapping many variables",
    "text": "Mapping many variables\n\n\n\n\nlibrary(\"palmerpenguins\")\n\ndata(\"penguins\")\n\npenguins %&gt;%\n        ggplot(aes(x = flipper_length_mm, \n                   y = body_mass_g, \n                   color = species, \n                   shape = sex, \n                   size = bill_length_mm)) + \n        geom_point()"
  },
  {
    "objectID": "02-datavis.html#mapping-many-variables-and-adding-facets",
    "href": "02-datavis.html#mapping-many-variables-and-adding-facets",
    "title": "Data visualization",
    "section": "Mapping many variables and adding facets",
    "text": "Mapping many variables and adding facets\n\n\n\n\nlibrary(\"palmerpenguins\")\n\ndata(\"penguins\")\n\npenguins %&gt;%\n        ggplot(aes(x = flipper_length_mm, \n                   y = body_mass_g, \n                   color = species, \n                   shape = sex,\n                   size = bill_length_mm)) + \n        geom_point() + \n        facet_wrap(~ year)"
  },
  {
    "objectID": "02-datavis.html#changing-non-data-aspects-of-the-plot-theme",
    "href": "02-datavis.html#changing-non-data-aspects-of-the-plot-theme",
    "title": "Data visualization",
    "section": "Changing non-data aspects of the plot (theme())",
    "text": "Changing non-data aspects of the plot (theme())\n\n\n\n\nlibrary(\"palmerpenguins\")\n\ndata(\"penguins\")\n\npenguins %&gt;%\n        ggplot(aes(x = flipper_length_mm, \n                   y = body_mass_g, \n                   color = species, \n                   shape = sex, \n                   size = bill_length_mm)) + \n        geom_point() + \n        \n        theme_dark()"
  },
  {
    "objectID": "02-datavis.html#common-types-of-plots---frequencies-and-densities",
    "href": "02-datavis.html#common-types-of-plots---frequencies-and-densities",
    "title": "Data visualization",
    "section": "Common types of plots - Frequencies and densities",
    "text": "Common types of plots - Frequencies and densities\n\nA continuous variable displayed in a Histogram and Density plot"
  },
  {
    "objectID": "02-datavis.html#common-types-of-plots---comparing-categories",
    "href": "02-datavis.html#common-types-of-plots---comparing-categories",
    "title": "Data visualization",
    "section": "Common types of plots - Comparing categories",
    "text": "Common types of plots - Comparing categories\n\nComparison of a continous variable between categories using summary graphics"
  },
  {
    "objectID": "02-datavis.html#common-types-of-plots---comparing-categories-without-hiding-data",
    "href": "02-datavis.html#common-types-of-plots---comparing-categories-without-hiding-data",
    "title": "Data visualization",
    "section": "Common types of plots - Comparing categories without hiding data",
    "text": "Common types of plots - Comparing categories without hiding data\n\nComparison of a continous variable between categories using summary graphics"
  },
  {
    "objectID": "02-datavis.html#common-types-of-plots---comparing-categories-highlighting-differences",
    "href": "02-datavis.html#common-types-of-plots---comparing-categories-highlighting-differences",
    "title": "Data visualization",
    "section": "Common types of plots - Comparing categories highlighting differences",
    "text": "Common types of plots - Comparing categories highlighting differences\n\nComparison of a continous variable between categories using raw data and summaries"
  },
  {
    "objectID": "02-datavis.html#common-types-of-plots---relationships-between-continuous-variables",
    "href": "02-datavis.html#common-types-of-plots---relationships-between-continuous-variables",
    "title": "Data visualization",
    "section": "Common types of plots - Relationships between continuous variables",
    "text": "Common types of plots - Relationships between continuous variables\n\nHighlighting relationships, raw data and summaries"
  },
  {
    "objectID": "02-datavis.html#references",
    "href": "02-datavis.html#references",
    "title": "Data visualization",
    "section": "References",
    "text": "References\n\n\n\n\n\n\nAnscombe, F. J. 1973. “Graphs in Statistical Analysis.” The American Statistician 27 (1): 17. https://doi.org/10.2307/2682899.\n\n\nWickham, Hadley. 2010. “A Layered Grammar of Graphics.” Journal of Computational and Graphical Statistics 19 (1): 3–28. https://doi.org/10.1198/jcgs.2009.07098."
  },
  {
    "objectID": "03-data-wrangling-homework.html#variables",
    "href": "03-data-wrangling-homework.html#variables",
    "title": "Creating tables - Homework",
    "section": "Variables",
    "text": "Variables\n\nThe data are part of the exscidata package.\nTo load the data and check variable names:\n\n\nlibrary(tidyverse); library(gt); library(exscidata)\n\ncolnames(hypertrophy)\n\n  [1] \"PARTICIPANT\"              \"GROUP\"                   \n  [3] \"AGE\"                      \"HEIGHT\"                  \n  [5] \"TRAINING_AGE\"             \"BODYMASS_T2\"             \n  [7] \"VL_T1\"                    \"VL_T2\"                   \n  [9] \"VL_T3\"                    \"VL_T4\"                   \n [11] \"BICEPS_T1\"                \"BICEPS_T2\"               \n [13] \"BICEPS_T3\"                \"BICEPS_T4\"               \n [15] \"ECW_T1\"                   \"ECW_T2\"                  \n [17] \"ECW_T3\"                   \"ECW_T4\"                  \n [19] \"ICW_T1\"                   \"ICW_T2\"                  \n [21] \"ICW_T3\"                   \"ICW_T4\"                  \n [23] \"TBW_T1\"                   \"TBW_T2\"                  \n [25] \"TBW_T3\"                   \"TBW_T4\"                  \n [27] \"TOTAL_VOLUME_LOAD_WEEK_1\" \"TOTAL_VOLUME_LOAD_WEEK_2\"\n [29] \"TOTAL_VOLUME_LOAD_WEEK_3\" \"TOTAL_VOLUME_LOAD_WEEK_4\"\n [31] \"TOTAL_VOLUME_LOAD_WEEK_5\" \"TOTAL_VOLUME_LOAD_WEEK_6\"\n [33] \"CALS_WEEK_1\"              \"CALS_WEEK_2\"             \n [35] \"CALS_WEEK_3\"              \"CALS_WEEK_4\"             \n [37] \"CALS_WEEK_5\"              \"CALS_WEEK_6\"             \n [39] \"PROTEIN_WEEK_1\"           \"PROTEIN_WEEK_2\"          \n [41] \"PROTEIN_WEEK_3\"           \"PROTEIN_WEEK_4\"          \n [43] \"PROTEIN_WEEK_5\"           \"PROTEIN_WEEK_6\"          \n [45] \"CHO_WEEK_1\"               \"CHO_WEEK_2\"              \n [47] \"CHO_WEEK_3\"               \"CHO_WEEK_4\"              \n [49] \"CHO_WEEK_5\"               \"CHO_WEEK_6\"              \n [51] \"FAT_WEEK_1\"               \"FAT_WEEK_2\"              \n [53] \"FAT_WEEK_3\"               \"FAT_WEEK_4\"              \n [55] \"FAT_WEEK_5\"               \"FAT_WEEK_6\"              \n [57] \"TMD_T1\"                   \"TMD_T2\"                  \n [59] \"TMD_T3\"                   \"PPT_AVG_T1\"              \n [61] \"PPT_AVG_T2\"               \"PPT_AVG_T3\"              \n [63] \"BODYMASS_T1\"              \"BODYMASS_T3\"             \n [65] \"SQUAT_3RM\"                \"SQUAT_VOLUME\"            \n [67] \"CLUSTER\"                  \"PERCENT_TYPE_I_T1\"       \n [69] \"PERCENT_TYPE_II_T1\"       \"FAST_CSA_T1\"             \n [71] \"FAST_CSA_T2\"              \"FAST_CSA_T3\"             \n [73] \"SLOW_CSA_T1\"              \"SLOW_CSA_T2\"             \n [75] \"SLOW_CSA_T3\"              \"FAST_NUCLEI_T1\"          \n [77] \"FAST_NUCLEI_T2\"           \"FAST_NUCLEI_T3\"          \n [79] \"SLOW_NUCLEI_T1\"           \"SLOW_NUCLEI_T2\"          \n [81] \"SLOW_NUCLEI_T3\"           \"AR_PROTEIN_T1\"           \n [83] \"AR_PROTEIN_T2\"            \"AR_PROTEIN_T3\"           \n [85] \"PROTEASOME_T1\"            \"PROTEASOME_T2\"           \n [87] \"PROTEASOME_T3\"            \"GLYCOGEN_T1\"             \n [89] \"GLYCOGEN_T2\"              \"GLYCOGEN_T3\"             \n [91] \"CS_T1\"                    \"CS_T2\"                   \n [93] \"CS_T3\"                    \"CK_T1\"                   \n [95] \"CK_T2\"                    \"CK_T3\"                   \n [97] \"TESTOSTERONE_T1\"          \"TESTOSTERONE_T2\"         \n [99] \"TESTOSTERONE_T3\"          \"CORTISOL_T1\"             \n[101] \"CORTISOL_T2\"              \"CORTISOL_T3\"             \n[103] \"PAN4EBP1_T1\"              \"PAN4EBP1_T2\"             \n[105] \"PAN4EBP1_T3\"              \"PHOSPHO4EBP1_T1\"         \n[107] \"PHOSPHO4EBP1_T2\"          \"PHOSPHO4EBP1_T3\"         \n[109] \"PANMTOR_T1\"               \"PANMTOR_T2\"              \n[111] \"PANMTOR_T3\"               \"PHOSPHOMTOR_T1\"          \n[113] \"PHOSPHOMTOR_T2\"           \"PHOSPHOMTOR_T3\"          \n[115] \"PANAMPK_T1\"               \"PANAMPK_T2\"              \n[117] \"PANAMPK_T3\"               \"PHOSPHOAMPK_T1\"          \n[119] \"PHOSPHOAMPK_T2\"           \"PHOSPHOAMPK_T3\"          \n[121] \"PANP70S6K_T1\"             \"PANP70S6K_T2\"            \n[123] \"PANP70S6K_T3\"             \"PHOSPHOP70S6K_T1\"        \n[125] \"PHOSPHOP70S6K_T2\"         \"PHOSPHOP70S6K_T3\"        \n[127] \"PANPOLYUB_T1\"             \"PANPOLYUB_T2\"            \n[129] \"PANPOLYUB_T3\"             \"RNA_T1\"                  \n[131] \"RNA_T2\"                   \"RNA_T3\"                  \n[133] \"MGF_T2T1_FOLD_CHANGE\"     \"MGF_T3T1_FOLD_CHANGE\"    \n[135] \"MGF_T1\"                   \"MSTN_T2T1_FOLD_CHANGE\"   \n[137] \"MSTN_T3T1_FOLD_CHANGE\"    \"MSTN_T1\"                 \n[139] \"RNA45S_T1\"                \"RNA45S_T2T1_FOLD_CHANGE\" \n[141] \"RNA45S_T3T1_FOLD_CHANGE\"  \"DXA_LBM_T1\"              \n[143] \"DXA_LBM_T2\"               \"DXA_LBM_T3\"              \n[145] \"DXA_FM_T1\"                \"DXA_FM_T2\"               \n[147] \"DXA_FM_T3\""
  },
  {
    "objectID": "03-data-wrangling-homework.html#variables-in-the-table-some-are-missing-from-the-data",
    "href": "03-data-wrangling-homework.html#variables-in-the-table-some-are-missing-from-the-data",
    "title": "Creating tables - Homework",
    "section": "Variables in the table, some are missing from the data",
    "text": "Variables in the table, some are missing from the data\n\nhypertrophy %&gt;%\n        select(GROUP, AGE, \n               HEIGHT, \n               BODYMASS_T1, \n               DXA_LBM_T1, \n               DXA_FM_T1, \n               SQUAT_3RM) %&gt;%\n        head()\n\n# A tibble: 6 × 7\n  GROUP   AGE HEIGHT BODYMASS_T1 DXA_LBM_T1 DXA_FM_T1 SQUAT_3RM\n  &lt;chr&gt; &lt;dbl&gt;  &lt;dbl&gt;       &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 WP       22   186         91.6       69.6     17.3        152\n2 WP       20   179         82         63.9     15.6        125\n3 GWP      24   178         77.7       66.0      9.37       143\n4 GWP      22   183         94.2       70.8     19.8        134\n5 MALTO    19   169         71         56.2     12.1        138\n6 WP       20   178.        83.4       57.5     22.6        147\n\n## Missing variables: Bench press, Deadlift, Lat pulldown, Overhead press"
  },
  {
    "objectID": "03-data-wrangling-homework.html#grouping-and-summarising",
    "href": "03-data-wrangling-homework.html#grouping-and-summarising",
    "title": "Creating tables - Homework",
    "section": "Grouping and summarising",
    "text": "Grouping and summarising\n\nThe table shows data per group and across all groups.\nI will first create a summary of groups the across all groups.\n\n\ngroup_wise &lt;- hypertrophy %&gt;%\n                select(GROUP,AGE, HEIGHT, BODYMASS_T1,DXA_LBM_T1, DXA_FM_T1, \n                        SQUAT_3RM) %&gt;%\n        pivot_longer(names_to = \"variable\", \n                     values_to = \"value\", \n                     cols = AGE:SQUAT_3RM) %&gt;%\n        \n        summarise(m = mean(value), \n                  s = sd(value), \n                  .by = c(GROUP, variable)) %&gt;%\n        print()\n\n# A tibble: 18 × 4\n   GROUP variable        m     s\n   &lt;chr&gt; &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt;\n 1 WP    AGE          21.4  2.37\n 2 WP    HEIGHT      178.   5.60\n 3 WP    BODYMASS_T1  82.2  8.70\n 4 WP    DXA_LBM_T1   63.7  7.11\n 5 WP    DXA_FM_T1    15.2  4.15\n 6 WP    SQUAT_3RM   134.  21.4 \n 7 GWP   AGE          22.3  2.24\n 8 GWP   HEIGHT      183.   7.39\n 9 GWP   BODYMASS_T1  NA   NA   \n10 GWP   DXA_LBM_T1   NA   NA   \n11 GWP   DXA_FM_T1    NA   NA   \n12 GWP   SQUAT_3RM    NA   NA   \n13 MALTO AGE          20.7  1.57\n14 MALTO HEIGHT      178.   9.56\n15 MALTO BODYMASS_T1  81.4 10.7 \n16 MALTO DXA_LBM_T1   62.1  8.44\n17 MALTO DXA_FM_T1    16.1  3.55\n18 MALTO SQUAT_3RM   126   17.2"
  },
  {
    "objectID": "03-data-wrangling-homework.html#it-seems-we-have-missing-data",
    "href": "03-data-wrangling-homework.html#it-seems-we-have-missing-data",
    "title": "Creating tables - Homework",
    "section": "It seems we have missing data",
    "text": "It seems we have missing data\n\nAdding two variables to get more control\n\n\ngroup_wise &lt;- hypertrophy %&gt;%\n                select(GROUP,AGE, HEIGHT, BODYMASS_T1,DXA_LBM_T1, DXA_FM_T1, \n                        SQUAT_3RM) %&gt;%\n        pivot_longer(names_to = \"variable\", \n                     values_to = \"value\", \n                     cols = AGE:SQUAT_3RM) %&gt;%\n        \n        summarise(m = mean(value, na.rm = TRUE), \n                  s = sd(value, na.rm = TRUE), \n                  miss_val = sum(is.na(value)),\n                  n = n(),\n                  .by = c(GROUP, variable)) %&gt;%\n        print()\n\n# A tibble: 18 × 6\n   GROUP variable        m     s miss_val     n\n   &lt;chr&gt; &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt;    &lt;int&gt; &lt;int&gt;\n 1 WP    AGE          21.4  2.37        0    10\n 2 WP    HEIGHT      178.   5.60        0    10\n 3 WP    BODYMASS_T1  82.2  8.70        0    10\n 4 WP    DXA_LBM_T1   63.7  7.11        0    10\n 5 WP    DXA_FM_T1    15.2  4.15        0    10\n 6 WP    SQUAT_3RM   134.  21.4         0    10\n 7 GWP   AGE          22.3  2.24        0    11\n 8 GWP   HEIGHT      183.   7.39        0    11\n 9 GWP   BODYMASS_T1  85.1 15.0         1    11\n10 GWP   DXA_LBM_T1   68.2 10.8         1    11\n11 GWP   DXA_FM_T1    13.4  4.77        1    11\n12 GWP   SQUAT_3RM   134.  20.6         1    11\n13 MALTO AGE          20.7  1.57        0    10\n14 MALTO HEIGHT      178.   9.56        0    10\n15 MALTO BODYMASS_T1  81.4 10.7         0    10\n16 MALTO DXA_LBM_T1   62.1  8.44        0    10\n17 MALTO DXA_FM_T1    16.1  3.55        0    10\n18 MALTO SQUAT_3RM   126   17.2         0    10"
  },
  {
    "objectID": "03-data-wrangling-homework.html#wrangling-to-a-wide-format",
    "href": "03-data-wrangling-homework.html#wrangling-to-a-wide-format",
    "title": "Creating tables - Homework",
    "section": "Wrangling to a wide format",
    "text": "Wrangling to a wide format\n\ngroup_wise &lt;- group_wise %&gt;%\n        select(GROUP:s) %&gt;%\n        pivot_wider(names_from = GROUP, \n                    values_from = c(m ,s)) %&gt;%\n        \n        select(variable, \n               m_WP, s_WP,\n               m_GWP, s_GWP, \n               m_MALTO, s_MALTO) %&gt;%\n                \n        print()\n\n# A tibble: 6 × 7\n  variable     m_WP  s_WP m_GWP s_GWP m_MALTO s_MALTO\n  &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1 AGE          21.4  2.37  22.3  2.24    20.7    1.57\n2 HEIGHT      178.   5.60 183.   7.39   178.     9.56\n3 BODYMASS_T1  82.2  8.70  85.1 15.0     81.4   10.7 \n4 DXA_LBM_T1   63.7  7.11  68.2 10.8     62.1    8.44\n5 DXA_FM_T1    15.2  4.15  13.4  4.77    16.1    3.55\n6 SQUAT_3RM   134.  21.4  134.  20.6    126     17.2"
  },
  {
    "objectID": "03-data-wrangling-homework.html#summarising-across-groups",
    "href": "03-data-wrangling-homework.html#summarising-across-groups",
    "title": "Creating tables - Homework",
    "section": "Summarising across groups",
    "text": "Summarising across groups\n\ntotal &lt;- hypertrophy %&gt;%\n                select(GROUP,AGE, HEIGHT, BODYMASS_T1,DXA_LBM_T1, DXA_FM_T1, \n                        SQUAT_3RM) %&gt;%\n        pivot_longer(names_to = \"variable\", \n                     values_to = \"value\", \n                     cols = AGE:SQUAT_3RM) %&gt;%\n        \n        summarise(m = mean(value, na.rm = TRUE), \n                  s = sd(value, na.rm = TRUE), \n                  miss_val = sum(is.na(value)),\n                  n = n(),\n                  .by = c(variable)) %&gt;%\n        print()\n\n# A tibble: 6 × 5\n  variable        m     s miss_val     n\n  &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt;    &lt;int&gt; &lt;int&gt;\n1 AGE          21.5  2.13        0    31\n2 HEIGHT      180.   7.91        0    31\n3 BODYMASS_T1  82.9 11.5         1    31\n4 DXA_LBM_T1   64.7  9.02        1    31\n5 DXA_FM_T1    14.9  4.20        1    31\n6 SQUAT_3RM   131.  19.5         1    31"
  },
  {
    "objectID": "03-data-wrangling-homework.html#combining-group-wise-and-total-summaries-1",
    "href": "03-data-wrangling-homework.html#combining-group-wise-and-total-summaries-1",
    "title": "Creating tables - Homework",
    "section": "Combining group-wise and total summaries (1)",
    "text": "Combining group-wise and total summaries (1)\n\ngroup_wise %&gt;%\n        inner_join(total) %&gt;%\n        print()\n\nJoining with `by = join_by(variable)`\n\n\n# A tibble: 6 × 11\n  variable     m_WP  s_WP m_GWP s_GWP m_MALTO s_MALTO     m     s miss_val     n\n  &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;int&gt; &lt;int&gt;\n1 AGE          21.4  2.37  22.3  2.24    20.7    1.57  21.5  2.13        0    31\n2 HEIGHT      178.   5.60 183.   7.39   178.     9.56 180.   7.91        0    31\n3 BODYMASS_T1  82.2  8.70  85.1 15.0     81.4   10.7   82.9 11.5         1    31\n4 DXA_LBM_T1   63.7  7.11  68.2 10.8     62.1    8.44  64.7  9.02        1    31\n5 DXA_FM_T1    15.2  4.15  13.4  4.77    16.1    3.55  14.9  4.20        1    31\n6 SQUAT_3RM   134.  21.4  134.  20.6    126     17.2  131.  19.5         1    31"
  },
  {
    "objectID": "03-data-wrangling-homework.html#combining-group-wise-and-total-summaries-2",
    "href": "03-data-wrangling-homework.html#combining-group-wise-and-total-summaries-2",
    "title": "Creating tables - Homework",
    "section": "Combining group-wise and total summaries (2)",
    "text": "Combining group-wise and total summaries (2)\n\ncbind(group_wise, total[,c(2,3)])\n\n     variable    m_WP      s_WP     m_GWP     s_GWP m_MALTO   s_MALTO         m\n1         AGE  21.400  2.366432  22.27273  2.240130  20.700  1.567021  21.48387\n2      HEIGHT 177.850  5.597867 183.45455  7.390719 177.750  9.563385 179.80645\n3 BODYMASS_T1  82.190  8.699355  85.14000 14.951938  81.350 10.701947  82.89333\n4  DXA_LBM_T1  63.732  7.107267  68.24200 10.840768  62.058  8.436904  64.67733\n5   DXA_FM_T1  15.181  4.146110  13.39200  4.770725  16.101  3.546486  14.89133\n6   SQUAT_3RM 134.500 21.422989 133.50000 20.560210 126.000 17.185265 131.33333\n          s\n1  2.127142\n2  7.912730\n3 11.451816\n4  9.016394\n5  4.196470\n6 19.497716"
  },
  {
    "objectID": "03-data-wrangling-homework.html#formatting-the-table-gt",
    "href": "03-data-wrangling-homework.html#formatting-the-table-gt",
    "title": "Creating tables - Homework",
    "section": "Formatting the table (gt)",
    "text": "Formatting the table (gt)\n\ntbl &lt;- group_wise %&gt;%\n        inner_join(total) %&gt;%\n        select(variable:s) %&gt;%\n        mutate(variable = factor(variable, \n                                 levels = c(\"AGE\", \"HEIGHT\", \"BODYMASS_T1\", \n                                            \"DXA_LBM_T1\", \"DXA_FM_T1\", \n                                            \"SQUAT_3RM\"), \n                                 labels = c(\"Age (years)\", \n                                            \"Height (cm)\", \n                                            \"Weight (kg)\", \n                                            \"Total lean mass (kg)\", \n                                            \"Total fat mass (kg)\", \n                                            \"Squat 3RM (kg)\"))) %&gt;%\n        gt() %&gt;%\n        fmt_number(columns = m_WP:s, \n                   decimals = 2) %&gt;%\n        cols_merge(columns = c(m_WP, s_WP), \n                   pattern = \"{1} &plusmn; {2}\") %&gt;%\n        cols_merge(columns = c(m_GWP, s_GWP), \n                   pattern = \"{1} &plusmn; {2}\") %&gt;%\n        cols_merge(columns = c(m_MALTO, s_MALTO), \n                   pattern = \"{1} &plusmn; {2}\") %&gt;%\n        cols_merge(columns = c(m, s), \n                   pattern = \"{1} &plusmn; {2}\")\n\nJoining with `by = join_by(variable)`"
  },
  {
    "objectID": "03-data-wrangling-homework.html#fixing-column-names-and-footnotes",
    "href": "03-data-wrangling-homework.html#fixing-column-names-and-footnotes",
    "title": "Creating tables - Homework",
    "section": "Fixing column names and footnotes",
    "text": "Fixing column names and footnotes\n\n# Calculate n participants per group\nlabels &lt;- hypertrophy %&gt;%\n        summarise(.by = GROUP, \n                  n = n()) %&gt;%\n        add_row(GROUP = \"Total\")%&gt;%\n        \n        mutate(n = if_else(is.na(n), sum(n, na.rm = TRUE), n),\n               label = paste0(GROUP, \" (n = \",n, \")\")) \n\n## Store labels as a list\ncol_labs &lt;- as.list(labels$label)\n## Name the element of the list\nnames(col_labs) &lt;- c(\"m_WP\", \"m_GWP\",  \"m_MALTO\", \"m\")\n\n\ntbl &lt;- tbl %&gt;%\n        # cols_label accepts a list as input\n        cols_label(.list = col_labs) %&gt;%\n        # cols_label also accepts &lt;column name&gt; = &lt;label&gt;\n        cols_label(variable = \"Variable\")"
  },
  {
    "objectID": "03-data-wrangling-homework.html#last-touch",
    "href": "03-data-wrangling-homework.html#last-touch",
    "title": "Creating tables - Homework",
    "section": "Last touch",
    "text": "Last touch\n\ntbl %&gt;%\n        cols_align(align = \"center\", \n                   columns = starts_with(\"m\")) %&gt;%\n         cols_align(align = \"left\", \n                   columns = starts_with(\"v\"))  %&gt;%\n          tab_style(\n    style = list(\n      cell_text(weight = \"bold\")\n    ),\n    locations = cells_column_labels(everything())\n  ) %&gt;% \n        \n        \n        tab_footnote(footnote = md(\"*All data presented as means &plusmn; standard deviation values.*\"))\n\n\n\n\n\n  \n    \n    \n      Variable\n      WP (n = 10)\n      GWP (n = 11)\n      MALTO (n = 10)\n      Total (n = 31)\n    \n  \n  \n    Age (years)\n21.40 ± 2.37\n22.27 ± 2.24\n20.70 ± 1.57\n21.48 ± 2.13\n    Height (cm)\n177.85 ± 5.60\n183.45 ± 7.39\n177.75 ± 9.56\n179.81 ± 7.91\n    Weight (kg)\n82.19 ± 8.70\n85.14 ± 14.95\n81.35 ± 10.70\n82.89 ± 11.45\n    Total lean mass (kg)\n63.73 ± 7.11\n68.24 ± 10.84\n62.06 ± 8.44\n64.68 ± 9.02\n    Total fat mass (kg)\n15.18 ± 4.15\n13.39 ± 4.77\n16.10 ± 3.55\n14.89 ± 4.20\n    Squat 3RM (kg)\n134.50 ± 21.42\n133.50 ± 20.56\n126.00 ± 17.19\n131.33 ± 19.50\n  \n  \n  \n    \n       All data presented as means ± standard deviation values.\n    \n  \n\n\n\n?tab_style\n\nstarting httpd help server ... done"
  },
  {
    "objectID": "03-data-wrangling.html#tidy-tabular-data",
    "href": "03-data-wrangling.html#tidy-tabular-data",
    "title": "Data wrangling",
    "section": "Tidy tabular data",
    "text": "Tidy tabular data\n\nTidy tabular data has\n\nOne variable per column\nOne observation per row\nOne value per cell"
  },
  {
    "objectID": "03-data-wrangling.html#data-wrangling",
    "href": "03-data-wrangling.html#data-wrangling",
    "title": "Data wrangling",
    "section": "Data wrangling",
    "text": "Data wrangling\n\n\n\n“Data analysts typically spend the majority of their time in the process of data wrangling compared to the actual analysis of the data.”"
  },
  {
    "objectID": "03-data-wrangling.html#data-wrangling-1",
    "href": "03-data-wrangling.html#data-wrangling-1",
    "title": "Data wrangling",
    "section": "Data wrangling",
    "text": "Data wrangling\n\nAggregation through summaries\n\nE.g. variables are summarized over multiple observations\n\nTransformation of data\n\nE.g. new variables are created on existing data\n\nArranging data\n\nE.g. sorting data based on values of observations"
  },
  {
    "objectID": "03-data-wrangling.html#dplyr",
    "href": "03-data-wrangling.html#dplyr",
    "title": "Data wrangling",
    "section": "dplyr",
    "text": "dplyr\n\ndplyr provides verbs for wrangling data\n“Translate thoughts to code”\nUsing the package we can\n\nmutate (create) new variables\nselect variables\nfilter observations\nsummarise values\narrange observations or rows"
  },
  {
    "objectID": "03-data-wrangling.html#r-functions",
    "href": "03-data-wrangling.html#r-functions",
    "title": "Data wrangling",
    "section": "R functions",
    "text": "R functions\n\nFunctions are created to perform a specific task\nFunctions exists in packages, or as user specified in your environment\nFunction (can) take arguments as input\n\n\n1important_function(arg1 = \"A\", arg2 = \"B\")\n2important_function(\"A\", \"B\")\n3important_function()\n\n\n1\n\nArguments are named.\n\n2\n\nArguments are used by their position\n\n3\n\nThe function is used with default argument values"
  },
  {
    "objectID": "03-data-wrangling.html#r-functions-in-tidyverse",
    "href": "03-data-wrangling.html#r-functions-in-tidyverse",
    "title": "Data wrangling",
    "section": "R functions in tidyverse",
    "text": "R functions in tidyverse\n\nFunctions that are specifically written for the tidyverse are “pipeable”, the data argument has the first position, an example\n\n\n1pipe_function(data = my.data, arg2 = \"a\", arg3 = \"b\", arg4 = \"etc\")\n2pipe_function(my.data, arg2 = \"a\", arg3 = \"b\", arg4 = \"etc\")\n3pipe_function(my.data)\n\n\n1\n\nAll arguments are named.\n\n2\n\nThe first argument not names, specified by position\n\n3\n\nThe function is used with default argument values, except the first argument data"
  },
  {
    "objectID": "03-data-wrangling.html#data-pipes",
    "href": "03-data-wrangling.html#data-pipes",
    "title": "Data wrangling",
    "section": "Data pipes",
    "text": "Data pipes\n\n\n\nUsing pipes we can execute data verbs in sequence\nThe pipe operator passes the “left hand” data to the first position in the following function.\n\n\n# This is equivalent...\ndata |&gt;\n        pipe_function() \n# ... to this\npipe_function(data)"
  },
  {
    "objectID": "03-data-wrangling.html#why-pipe",
    "href": "03-data-wrangling.html#why-pipe",
    "title": "Data wrangling",
    "section": "Why pipe?",
    "text": "Why pipe?\n\nPiping makes code more readable, an example\n\n\n# No pipes\nprint(fun_c(fun_b(fun_a(data))))\n\n# Using pipes\ndata |&gt;\n        fun_a() |&gt;\n        fun_b() |&gt;\n        fun_c() |&gt;\n        print()"
  },
  {
    "objectID": "03-data-wrangling.html#pipes-in-r",
    "href": "03-data-wrangling.html#pipes-in-r",
    "title": "Data wrangling",
    "section": "Pipes in R",
    "text": "Pipes in R\n\n\n\nTwo “pipe-operators” are available in R\n\n|&gt; exists in base R\n%&gt;% is loaded with tidyverse as part of the magrittr package"
  },
  {
    "objectID": "03-data-wrangling.html#two-pipe-operators-in-action",
    "href": "03-data-wrangling.html#two-pipe-operators-in-action",
    "title": "Data wrangling",
    "section": "Two pipe operators in action",
    "text": "Two pipe operators in action\n\n\n\nlibrary(dplyr)\n\ndata |&gt;\n filter(var1 &gt; 10) |&gt;\n mutate(var3 = var1 + var2) |&gt;\n select(var1, varX) |&gt;\n print()\n\n\n\nlibrary(dplyr)\n\ndata %&gt;% \n filter(var1 &gt; 10) %&gt;% \n mutate(var3 = var1 + var2) %&gt;% \n select(var1, varX) %&gt;% \n print()"
  },
  {
    "objectID": "03-data-wrangling.html#data-placeholder",
    "href": "03-data-wrangling.html#data-placeholder",
    "title": "Data wrangling",
    "section": "Data placeholder",
    "text": "Data placeholder\n\nIf the data argument is not the first argument in a function, use a placeholder\n\n\ndata %&gt;% \n        fun(argument)\n\n## Is equivalent to\ndata %&gt;% \n        fun(., argument)\n\n\n## If the data is to be used in another place we need the placeholder\ndata %&gt;% \n        fun(argument, data = .)"
  },
  {
    "objectID": "03-data-wrangling.html#data-placeholder-a-realistic-example-and-saving-output",
    "href": "03-data-wrangling.html#data-placeholder-a-realistic-example-and-saving-output",
    "title": "Data wrangling",
    "section": "Data placeholder a realistic example, and saving output",
    "text": "Data placeholder a realistic example, and saving output\n\nlibrary(exscidata); library(tidyverse)\n1model1 &lt;- cyclingstudy %&gt;%\n2        filter(timepoint == \"pre\") %&gt;%\n3        mutate(VO2max.kg = VO2.max / weight.T1) %&gt;%\n4        lm(tte ~ VO2max.kg, data = .)\n5summary(model1)\n\n\n1\n\nSpecifying an object for saving output, taking the cycling study data\n\n2\n\nFilter to keep only pre-intervention data\n\n3\n\nCreating a new variable, VO2max relative to body mass\n\n4\n\nFitting a linear regression model explaining time to exhaustion (tte) with VO2max\n\n5\n\nShowing the summary from the model"
  },
  {
    "objectID": "04-writing.html#basics-quarto-and-rmarkdown",
    "href": "04-writing.html#basics-quarto-and-rmarkdown",
    "title": "Writing reports in Quarto (or R markdown)",
    "section": "Basics: Quarto and Rmarkdown",
    "text": "Basics: Quarto and Rmarkdown\n\n\nQuarto and R Markdown a special kind of scripts where text and computer code can be combined to generate reports.\nUnder the hood, a report generator is converting code and plain text to an output format such as html, pdf or docx (more formats are available).\nQuarto is a new, well documented format that gives extra flexibility, but also requires installation of extra software.\nR Markdown is also, see e.g. R Markdown, R Markdown: The Definitive Guide"
  },
  {
    "objectID": "04-writing.html#code-execution-and-the-environment",
    "href": "04-writing.html#code-execution-and-the-environment",
    "title": "Writing reports in Quarto (or R markdown)",
    "section": "Code execution and the environment",
    "text": "Code execution and the environment\n\n\nWhen a quarto or Rmarkdown file is “knitted” or compiled, the source file looks for additional files in the same directory as the source file is saved.\nWorking in a RStudio projects makes it easy to work with the report interactively as you can use relative paths.\nRStudio has an excellent guide to its project feature"
  },
  {
    "objectID": "04-writing.html#rstudio-projects",
    "href": "04-writing.html#rstudio-projects",
    "title": "Writing reports in Quarto (or R markdown)",
    "section": "RStudio projects",
    "text": "RStudio projects\n\nA projects is a collection of settings together with a root directory.\nThis means that you will be able to work with relative paths.\nIf reading a csv file using relative paths, your code will look like this from a project.\n\n\ndat &lt;- read_csv(\"./data/my-data.csv\")"
  },
  {
    "objectID": "04-writing.html#absolute-paths",
    "href": "04-writing.html#absolute-paths",
    "title": "Writing reports in Quarto (or R markdown)",
    "section": "Absolute paths",
    "text": "Absolute paths\n\nIf your are using absolute paths, reaching the same operation could look like this\n\n\ndat &lt;- read_csv(\"C:/Users/Daniel/Dropbox/Some-folder/a-project/data/my-data.csv\")"
  },
  {
    "objectID": "04-writing.html#a-basic-structure-for-projects",
    "href": "04-writing.html#a-basic-structure-for-projects",
    "title": "Writing reports in Quarto (or R markdown)",
    "section": "A basic structure for projects",
    "text": "A basic structure for projects\n\nRStudio projects helps you create good habits for reproducible analysis as all analyses are conducted within a stand-alone folder structure. Your data and scripts can be shared.\nUse a basic structure for all projects:\n\nMy-project\n        |\n        |-.Rproj        (The project settings)\n        |--/data        (Contains all data needed for your analysis)\n        |--/R           (Contains all scripts/R-files)\n        |--/output      (Collection of all output files)"
  },
  {
    "objectID": "04-writing.html#writing-in-quartor-markdown",
    "href": "04-writing.html#writing-in-quartor-markdown",
    "title": "Writing reports in Quarto (or R markdown)",
    "section": "Writing in Quarto/R Markdown",
    "text": "Writing in Quarto/R Markdown\n\nThe basic syntax in quarto/R Markdown files is markdown. Markdown makes it easy to format text without point-and-click as all formatting can be added with syntax, example:\n\nThis text is an example of the markdown syntax which includes **bold**, *italic*,\n^super^ and ~subscript~ and ~~striketrough~~\nResulting in:\n\nThis text is an example of the markdown syntax which includes bold, italic, super and subscript and striketrough"
  },
  {
    "objectID": "04-writing.html#markdown---more-on-text-formatting-html",
    "href": "04-writing.html#markdown---more-on-text-formatting-html",
    "title": "Writing reports in Quarto (or R markdown)",
    "section": "Markdown - More on text formatting (html)",
    "text": "Markdown - More on text formatting (html)\n\n\n\n\nWe can also use html for &lt;sub&gt;subscripts&lt;/sub&gt;\nand &lt;sup&gt;superscript&lt;/sup&gt;\n\n\n\nWe can also use html for subscripts and superscript"
  },
  {
    "objectID": "04-writing.html#markdown---more-on-text-formatting-latex",
    "href": "04-writing.html#markdown---more-on-text-formatting-latex",
    "title": "Writing reports in Quarto (or R markdown)",
    "section": "Markdown - More on text formatting (latex)",
    "text": "Markdown - More on text formatting (latex)\n\n\n\nMathematical formulas can be added inline with $y_i \\sim \\operatorname{Normal}(\\mu_i, \\sigma)$\n\nor as a block, using\n\n$$\ny = \\beta_0 + \\beta_1 \\times x_1 + \\epsilon\n$$\n\n\n\nMathematical formulas can be added inline with \\(y_i \\sim \\operatorname{Normal}(\\mu_i, \\sigma)\\)\nor as a block, using\n\\[\ny = \\beta_0 + \\beta_1 \\times x_1 + \\epsilon\n\\]"
  },
  {
    "objectID": "04-writing.html#markdown-lists",
    "href": "04-writing.html#markdown-lists",
    "title": "Writing reports in Quarto (or R markdown)",
    "section": "Markdown lists",
    "text": "Markdown lists\n\n\nA list can be unordered and ordered\n\n* Item A\n    + Item x\n\n    \n1. Item 1\n2. Item 2\n    i) Item i\n\n\n\nA list can be unordered and ordered\n\nItem A\n\nItem x\n\n\n\n\nItem 1\nItem 2\n\nItem i"
  },
  {
    "objectID": "04-writing.html#markdown-tables",
    "href": "04-writing.html#markdown-tables",
    "title": "Writing reports in Quarto (or R markdown)",
    "section": "Markdown tables",
    "text": "Markdown tables\n\n\n\n| Left |Center|Right| \n| :--- |:---: |---:|\n|Text | Text| Text| \n|35| 3| 999|\n\n: A table caption\n\n\n\n\nA table caption\n\n\nLeft\nCenter\nRight\n\n\n\n\nText\nText\nText\n\n\n35\n3\n999"
  },
  {
    "objectID": "04-writing.html#adding-images",
    "href": "04-writing.html#adding-images",
    "title": "Writing reports in Quarto (or R markdown)",
    "section": "Adding images",
    "text": "Adding images\n\n\n![](img/inn-logo.svg)"
  },
  {
    "objectID": "04-writing.html#cross-referencing",
    "href": "04-writing.html#cross-referencing",
    "title": "Writing reports in Quarto (or R markdown)",
    "section": "Cross-referencing",
    "text": "Cross-referencing\n\nWith cross-referencing it is possible to reference images, tables, equations etc.\nA cross reference requires an identifier\n\n\n\n![](img/inn-logo.svg){#fig-inn}\n\nSee [@fig-inn] for an example ...\n\n\n\n\n\n\n\nFigure 1: Høgskolen i Innlandet logo\n\n\nSee Figure 1 for an example …"
  },
  {
    "objectID": "04-writing.html#code-chunk-options",
    "href": "04-writing.html#code-chunk-options",
    "title": "Writing reports in Quarto (or R markdown)",
    "section": "Code chunk options",
    "text": "Code chunk options\n\nOutput from code chunks can be tables, figures or text used in the report.\nCode chunk options lets you specify, for example\n\nFigure captions, figure short-captions\nIf code, messages or warnings should be shown\nLabels used for cross-referencing\nCaching (saving computations of a code block if unchanged)"
  },
  {
    "objectID": "04-writing.html#code-chunk-options-syntax",
    "href": "04-writing.html#code-chunk-options-syntax",
    "title": "Writing reports in Quarto (or R markdown)",
    "section": "Code chunk options syntax",
    "text": "Code chunk options syntax\n\n\n\n#| echo: false\n#| message: false\n#| warning: false\n#| label: fig-example\n#| fig-cap: \"An example figure\"\n\n\nlibrary(exscidata); library(tidyverse)\n\ncyclingstudy %&gt;%\n        ggplot(aes(weight.T1, height.T1)) + geom_point()\n\n\n\n\n\n\n\n\nFigure 2: An example figure"
  },
  {
    "objectID": "04-writing.html#inline-code",
    "href": "04-writing.html#inline-code",
    "title": "Writing reports in Quarto (or R markdown)",
    "section": "Inline code",
    "text": "Inline code\n\nCode may be included inline to include code generated outputs\n\n\na_variable &lt;- 3.14\n\n\nTo include the variable in the text:\n\n\nThe variable will be displayed here `r a_variable`"
  },
  {
    "objectID": "04-writing.html#bibliographies",
    "href": "04-writing.html#bibliographies",
    "title": "Writing reports in Quarto (or R markdown)",
    "section": "Bibliographies",
    "text": "Bibliographies\n\nBibliographies/Citations may be added to reports using a external bibliography file. A simple format is bibtex\nPubmed entries can be searched using TexMed\nIn the visual editor, bibliographies can be easily created\n\n\n---\ntitle: \"My document\"\nbibliography: \"resources/bibliography.bib\"\n---"
  },
  {
    "objectID": "04-writing.html#where-to-find-help",
    "href": "04-writing.html#where-to-find-help",
    "title": "Writing reports in Quarto (or R markdown)",
    "section": "Where to find help?",
    "text": "Where to find help?\n\nThe quarto documentation is really good.\nA lot of examples on quarto is available trough google!\n\nSee the."
  },
  {
    "objectID": "06-correlations.html#the-regression-model",
    "href": "06-correlations.html#the-regression-model",
    "title": "Associations - Regression and Correlation",
    "section": "The regression model",
    "text": "The regression model\n\nThe ordinary regression model \\(y_i = \\beta_0 + \\beta x_i + \\epsilon_i\\) gives us the relationship between two variables, \\(x\\) and \\(y\\).\nThe correlation can be used to describe the same relationship using a unit-less number between -1 and 1.\nA correlation of 0 indicate no association, a correlation close to 1 and -1 indicate association."
  },
  {
    "objectID": "06-correlations.html#the-relationship-between-training-volume-and-vastus-lateralis-thickness",
    "href": "06-correlations.html#the-relationship-between-training-volume-and-vastus-lateralis-thickness",
    "title": "Associations - Regression and Correlation",
    "section": "The relationship between training volume and vastus lateralis thickness",
    "text": "The relationship between training volume and vastus lateralis thickness\n\n\n\n\n\n\n\n\nAre assumptions met?\n\nNo apparent curve-linear relationship\nThere are no obvious outliers, and\nBoth variables are evenly distributed (normally distributed)"
  },
  {
    "objectID": "06-correlations.html#the-relationship-between-training-volume-and-vastus-lateralis-thickness-1",
    "href": "06-correlations.html#the-relationship-between-training-volume-and-vastus-lateralis-thickness-1",
    "title": "Associations - Regression and Correlation",
    "section": "The relationship between training volume and vastus lateralis thickness",
    "text": "The relationship between training volume and vastus lateralis thickness\n\n\n\n\n\n\n\n\n\nlibrary(exscidata)\n\ncor(hypertrophy$VL_T1, \n    hypertrophy$SQUAT_VOLUME, \n    use = \"complete.obs\")"
  },
  {
    "objectID": "06-correlations.html#using-the-correlation-for-inference",
    "href": "06-correlations.html#using-the-correlation-for-inference",
    "title": "Associations - Regression and Correlation",
    "section": "Using the correlation for inference",
    "text": "Using the correlation for inference\n\n\n\nWe might want to say something about the population from where we have gathered participants\nThe correlation coefficient can be used for hypothesis testing using the cor.test function\n\n\ncor.test(hypertrophy$VL_T1, \n         hypertrophy$SQUAT_VOLUME, \n    na.action = na.omit)\n\n\n\n\n\n    Pearson's product-moment correlation\n\ndata:  hypertrophy$VL_T1 and hypertrophy$SQUAT_VOLUME\nt = 3.335, df = 27, p-value = 0.00249\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.2164913 0.7568216\nsample estimates:\n      cor \n0.5401395"
  },
  {
    "objectID": "06-correlations.html#correlation-and-univariate-regression",
    "href": "06-correlations.html#correlation-and-univariate-regression",
    "title": "Associations - Regression and Correlation",
    "section": "Correlation and univariate regression",
    "text": "Correlation and univariate regression\n\n\n\nThe correlation coefficient is a simplification of a univariate regression.\nWe will get the same results from lm (\\(\\sqrt{R^2}\\)) as the estimate from cor.test\n\n\nreg_mod &lt;- lm(VL_T1 ~ SQUAT_VOLUME, \n              data = hypertrophy)\n        \ncor_res &lt;- with(hypertrophy, \n                cor.test(VL_T1, \n                         SQUAT_VOLUME))      \n\nsqrt(summary(reg_mod)$r.squared)\n\ncor_res$estimate\n\n\n\n\nR from lm \n0.5401395 \n\n\nCorrelation estimate from cor.test \n                         0.5401395"
  },
  {
    "objectID": "06-correlations.html#the-correlation-comes-in-many-forms",
    "href": "06-correlations.html#the-correlation-comes-in-many-forms",
    "title": "Associations - Regression and Correlation",
    "section": "The correlation comes in many forms",
    "text": "The correlation comes in many forms\n\nWhen assumptions about normally distributed variables and outliers are questioned we may use a rank-based correlation.\nSpearman’s or Kendall’s correlation coefficient are both alternatives to the Pearson correlation coefficient\nSpearman’s \\(\\rho\\) is simply the correlation coefficient calculated from ranked values"
  },
  {
    "objectID": "06-correlations.html#in-r",
    "href": "06-correlations.html#in-r",
    "title": "Associations - Regression and Correlation",
    "section": "In R",
    "text": "In R\n\n\n\n## Ranking is sensitive to missing values\ndat &lt;- hypertrophy %&gt;%\n        select(VL_T1, SQUAT_VOLUME) %&gt;%\n         filter(!is.na(VL_T1), \n               !is.na(SQUAT_VOLUME))\n\n# The spearman method\nwith(dat, \n     cor.test(VL_T1, \n              SQUAT_VOLUME, \n              method = \"spearman\"))\n\n# Pearson method on ranked data\nwith(dat, \n     cor.test(rank(VL_T1), \n              rank(SQUAT_VOLUME), \n              method = \"pearson\"))\n\n\n\n\n\n    Spearman's rank correlation rho\n\ndata:  VL_T1 and SQUAT_VOLUME\nS = 1609.8, p-value = 0.0005285\nalternative hypothesis: true rho is not equal to 0\nsample estimates:\n      rho \n0.6035045 \n\n\n\n    Pearson's product-moment correlation\n\ndata:  rank(VL_T1) and rank(SQUAT_VOLUME)\nt = 3.9329, df = 27, p-value = 0.0005285\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.3043080 0.7943169\nsample estimates:\n      cor \n0.6035045"
  },
  {
    "objectID": "06-correlations.html#many-types-of-associations",
    "href": "06-correlations.html#many-types-of-associations",
    "title": "Associations - Regression and Correlation",
    "section": "Many types of associations",
    "text": "Many types of associations\n\n\nA broader definition of association can include…\n\nDiffrences in body weight between sexes → sex (discrete) is associated with body weight (continuous)\nPrevalence of ACL injuries differ between sexes → sex (discrete) is associated with injury status (discrete).\n\nWe use numerous statistical tests to describe associations (t-test, ANOVA, regression, etc.)"
  },
  {
    "objectID": "06-correlations.html#associations-and-causality",
    "href": "06-correlations.html#associations-and-causality",
    "title": "Associations - Regression and Correlation",
    "section": "Associations and causality",
    "text": "Associations and causality\n\nFigure 1: US spending on science, space and technology is positively related to the number of suicied by hanging, strangulation and suffocation."
  },
  {
    "objectID": "06-correlations.html#associations-and-causality-1",
    "href": "06-correlations.html#associations-and-causality-1",
    "title": "Associations - Regression and Correlation",
    "section": "Associations and causality",
    "text": "Associations and causality\n\n\nAssociations are descriptive → We observe statistical associations without being able to infer causality\nControlled experiments can be used to infer causality → Using experiments we can intervene in a system and interpret associations as causal (intervention associated with outcome)\nUsing graphs we can draw assumptions about relationships among variables"
  },
  {
    "objectID": "06-correlations.html#the-experimental-treatment-e-is-causally-associated-with-the-outcome-o",
    "href": "06-correlations.html#the-experimental-treatment-e-is-causally-associated-with-the-outcome-o",
    "title": "Associations - Regression and Correlation",
    "section": "The experimental treatment (E) is causally associated with the outcome (O)",
    "text": "The experimental treatment (E) is causally associated with the outcome (O)"
  },
  {
    "objectID": "06-correlations.html#in-obeservational-settings-an-exposure-e-may-be-indirectly-related-to-an-outcome-o-trough-a-confounder-c",
    "href": "06-correlations.html#in-obeservational-settings-an-exposure-e-may-be-indirectly-related-to-an-outcome-o-trough-a-confounder-c",
    "title": "Associations - Regression and Correlation",
    "section": "In obeservational settings, an exposure (E) may be indirectly related to an outcome (O) trough a confounder (C)",
    "text": "In obeservational settings, an exposure (E) may be indirectly related to an outcome (O) trough a confounder (C)"
  },
  {
    "objectID": "06-correlations.html#summary",
    "href": "06-correlations.html#summary",
    "title": "Associations - Regression and Correlation",
    "section": "Summary",
    "text": "Summary\n\n\nThe correlation analysis can be seen as a simplified regression analysis\nCorrelation and regression are used to quantify associations\nAssociations are what we describe with (many) statistical tests\nAssociation do not imply causation\nGraphs can be used to draw assumptions about associations"
  },
  {
    "objectID": "07-statistical-inference.html#the-problem-with-inference",
    "href": "07-statistical-inference.html#the-problem-with-inference",
    "title": "The goal of inference",
    "section": "The problem withinference",
    "text": "The problem withinference\n\n\nAll swans are white (P &lt; 0.05)\n\n\n\n\nJJ Harrison (https://www.jjharrison.com.au/) - Own work CC BY-SA 4.0\n\n\n\nIt turns out that it is not that simple.\nThe P-value did not presented us the truth. It was just a number calculated from a laborious process that included sampling of data, calculation of summary statistics and P-value.\nThe P-value might not even mean what we think it means?"
  },
  {
    "objectID": "07-statistical-inference.html#what-does-the-p-value-mean",
    "href": "07-statistical-inference.html#what-does-the-p-value-mean",
    "title": "The goal of inference",
    "section": "What does the p-value mean?",
    "text": "What does the p-value mean?\n\n(Svetkey 2008)\nSvetkey et al. performed an intervention where overweight or obese individuals that had lost at least 4 kg in a first weight loss phase were randomized to maintain their weight on their own or receive either “personal contact” or “interactive technology” in a follow up phase."
  },
  {
    "objectID": "07-statistical-inference.html#what-does-the-p-value-mean-1",
    "href": "07-statistical-inference.html#what-does-the-p-value-mean-1",
    "title": "The goal of inference",
    "section": "What does the p-value mean?",
    "text": "What does the p-value mean?\nAll groups regained weight after randomization by a mean of 5.5 kg in the self-directed, 5.2 kg in the interactive technology–based, and 4.0 kg in the personal-contact group… Those in the personal-contact group regained a mean of 1.2 kg less than those in the interactive technology–based group (95% CI, 2.1-0.3 kg; P=.008)."
  },
  {
    "objectID": "07-statistical-inference.html#what-does-the-p-value-mean-svetkey-at-al",
    "href": "07-statistical-inference.html#what-does-the-p-value-mean-svetkey-at-al",
    "title": "The goal of inference",
    "section": "What does the p-value mean? Svetkey at al…",
    "text": "What does the p-value mean? Svetkey at al…\n\n\n…have absolutely disproved the null hypothesis (that there is no difference between the population means).\n… have found the probability of the null hypothesis being true.\n… have absolutely proved their experimental hypothesis (that there is a difference between the population means).\n\n\nQuestions adopted from (Dienes 2008)."
  },
  {
    "objectID": "07-statistical-inference.html#what-does-the-p-value-mean-svetkey-at-al-1",
    "href": "07-statistical-inference.html#what-does-the-p-value-mean-svetkey-at-al-1",
    "title": "The goal of inference",
    "section": "What does the p-value mean? Svetkey at al…",
    "text": "What does the p-value mean? Svetkey at al…\n\n\n… can deduce the probability of the experimental hypothesis being true.\n… know the probability that you are making the wrong decision, if you decided to reject the null hypothesis.\n… have a reliable experimental finding in the sense that if, hypothetically, the experiment were repeated a great number of times, you would obtain a significant result on 95 % of occasions.\n\n\nQuestions adopted from (Dienes 2008)."
  },
  {
    "objectID": "07-statistical-inference.html#drawing-inference-from-a-sample",
    "href": "07-statistical-inference.html#drawing-inference-from-a-sample",
    "title": "The goal of inference",
    "section": "Drawing inference from a sample",
    "text": "Drawing inference from a sample\n\n\nParticipants are recruited to an intervention and randomized to either receive a RED or BLUE pills.\nSystolic blood pressure after the intervention\nDo RED and BLUE pills affect blood pressure differently?\n\n\n\nWe recruit participants to a trial were they will, by random allocation, receive either a blue or a red pill\nWe are interested in the systolic blood pressure as a result of the intervention, to be able to say something about the population we want to know if the groups differ?"
  },
  {
    "objectID": "07-statistical-inference.html#the-results",
    "href": "07-statistical-inference.html#the-results",
    "title": "The goal of inference",
    "section": "The results",
    "text": "The results\n\n\nWe have measured BP in both groups after the intervention.\nIt turns out that we have a difference between the groups. But how can we be sure that is a difference that is due to the different pills? We would like to have a test were we compare our results to what can be expected if there were no differences between the pills.\nWe can achieve this by random permutations of the observed data…"
  },
  {
    "objectID": "07-statistical-inference.html#a-permutation-experiment",
    "href": "07-statistical-inference.html#a-permutation-experiment",
    "title": "The goal of inference",
    "section": "A permutation experiment",
    "text": "A permutation experiment\n\n\nThe observed data is re-ordered to create a new data set where differences between groups is not due to the randomization of pills. From these groups, we calculate the average difference between our new groups. This follows by another re-allocation of participants, and a new average difference.\nWe repeat this process 10000 times."
  },
  {
    "objectID": "07-statistical-inference.html#permutation",
    "href": "07-statistical-inference.html#permutation",
    "title": "The goal of inference",
    "section": "10 000 Permutation",
    "text": "10 000 Permutation\n\n\nMost differences, out of our 10000 permutations are close to 0. Some are greater than 2.5…"
  },
  {
    "objectID": "07-statistical-inference.html#permutation-and-our-result",
    "href": "07-statistical-inference.html#permutation-and-our-result",
    "title": "The goal of inference",
    "section": "10 000 Permutation and our result",
    "text": "10 000 Permutation and our result\n\n\nOur observed difference is 2.5. This is located in the tail of the distribution of average differences. But how unlikely is our results among a collection of randomly allocated participants where the intervention had no effect?"
  },
  {
    "objectID": "07-statistical-inference.html#how-unlikely-is-our-result-if-the-pills-had-no-effect",
    "href": "07-statistical-inference.html#how-unlikely-is-our-result-if-the-pills-had-no-effect",
    "title": "The goal of inference",
    "section": "How unlikely is our result if the pills had no effect?",
    "text": "How unlikely is our result if the pills had no effect?\n\n\nThe average observed difference was 2.47.\n167 reshuffled averages where equal to or greater than our observed result.\nThis represent a small fraction of the reshuffled differences, in fact…\n\\(p = \\frac{167}{10000} = 0.0167\\)"
  },
  {
    "objectID": "07-statistical-inference.html#to-account-for-both-extremes",
    "href": "07-statistical-inference.html#to-account-for-both-extremes",
    "title": "The goal of inference",
    "section": "To account for both extremes",
    "text": "To account for both extremes\n\n\nWhen allocating the pills we did not really know what to expect, we did not account for the direction of the effect in our last test.\nWe should compare our result to extreme results in both directions.\n167 averages were equal to or greater than our observed result, and 169 averages were equal to or smaller than an effect corresponding to the observed in the other direction.\n\\(p = \\frac{167 + 169}{10000} = 0.0336\\)"
  },
  {
    "objectID": "07-statistical-inference.html#what-is-enough-evidence-for-inference",
    "href": "07-statistical-inference.html#what-is-enough-evidence-for-inference",
    "title": "The goal of inference",
    "section": "What is enough evidence for inference?",
    "text": "What is enough evidence for inference?\n\nWe have produced a P-value!\nSo far, given our experiment, how do you define the P-value?\nIs the P-value low enough to conclude anything about our pills?"
  },
  {
    "objectID": "07-statistical-inference.html#references",
    "href": "07-statistical-inference.html#references",
    "title": "The goal of inference",
    "section": "References",
    "text": "References\n\n\n\n\n\n\nDienes, Zoltan. 2008. Understanding Psychology as a Science: An Introduction to Scientific and Statistical Inference. New York: Palgrave Macmillan.\n\n\nSvetkey, Laura P. 2008. “Comparison of Strategies for Sustaining Weight LossThe Weight Loss Maintenance Randomized Controlled Trial.” JAMA 299 (10): 1139. https://doi.org/10.1001/jama.299.10.1139."
  },
  {
    "objectID": "08-sampling-populations.html#population-and-sample",
    "href": "08-sampling-populations.html#population-and-sample",
    "title": "Estimating a sampling distribution",
    "section": "Population and sample",
    "text": "Population and sample\n\nWhen we are interested in continuous data, the sample mean is unbiased estimate of the population parameter (the population mean).\n\nThe population mean:\n\\[\\mu=\\frac{\\sum{X_i}}{N}\\]\nThe sample mean:\n\\[\\bar{x}=\\frac{\\sum{x_i}}{n}\\]"
  },
  {
    "objectID": "08-sampling-populations.html#measures-of-dispersion",
    "href": "08-sampling-populations.html#measures-of-dispersion",
    "title": "Estimating a sampling distribution",
    "section": "Measures of dispersion",
    "text": "Measures of dispersion\n\n\n\nCentral tendency is captured by the “center of gravity” in the data, however, we might also want to know something about its variation.\nThe population variance is the average (squared) difference from the mean\nAs the population parameters are unknown, we estimate them with our sample\n\n\n\\[\\sigma^2 =  \\frac{\\sum_{i=1}^{N}{(X_i-\\mu)^2}}{N}\\]\n\n\n\\[s^2 =\\frac{\\sum_{i=1}^{n}{(x_i-\\bar{x})^2}}{n-1}\\]"
  },
  {
    "objectID": "08-sampling-populations.html#the-sample-variance",
    "href": "08-sampling-populations.html#the-sample-variance",
    "title": "Estimating a sampling distribution",
    "section": "The sample variance",
    "text": "The sample variance\n\nThe sample variance is an unbiased estimate of the population if we use \\(n-1\\) otherwise we will tend to underestimate the population values.\n\n\\[s^2 =\\frac{\\sum_{i=1}^{n}{(x_i-\\bar{x})^2}}{n-1}\\]\n\nThe degrees of freedom (\\(n-1\\)) is the number of values that can vary independently in the sample. One sample is dependent on the other to produce the mean, all other can vary."
  },
  {
    "objectID": "08-sampling-populations.html#variance-and-the-standard-deviation",
    "href": "08-sampling-populations.html#variance-and-the-standard-deviation",
    "title": "Estimating a sampling distribution",
    "section": "Variance and the standard deviation",
    "text": "Variance and the standard deviation\n\nThe variance is the average squared deviation from the mean\nThe standard deviation (\\(s\\)) is the square root of the variance, thus on the same scale as the mean\n\n\\[s = \\sqrt{\\frac{\\sum{(x_i-\\bar{x})^2}}{n-1}}\\]\n\nThe standard deviation is still an estimate of the population SD"
  },
  {
    "objectID": "08-sampling-populations.html#sampling-distributions",
    "href": "08-sampling-populations.html#sampling-distributions",
    "title": "Estimating a sampling distribution",
    "section": "Sampling distributions",
    "text": "Sampling distributions\n\nAny statistic can be calculated from a sample and used as an estimation of the population parameter.\nAs an example, the sample mean (\\(\\bar{x}\\)) is an unbiased estimator of the population mean, we can know this because the average of repeated samples from a population will be close to the population mean (\\(\\mu\\)).\n\n\n\nGreat, on average, we will hit the spot on the population parameter!\nThis result is very convenient!\nThis also means that we can know something about the distribution of samples that is retrieved from an unknown population of values.\nThis is the basis for the central limit theorem."
  },
  {
    "objectID": "08-sampling-populations.html#the-distribution-of-samples-will-have-a-normal-shape-irrespective-of-the-underlying-population-distribution",
    "href": "08-sampling-populations.html#the-distribution-of-samples-will-have-a-normal-shape-irrespective-of-the-underlying-population-distribution",
    "title": "Estimating a sampling distribution",
    "section": "The distribution of samples will have a “normal” shape irrespective of the underlying population distribution!",
    "text": "The distribution of samples will have a “normal” shape irrespective of the underlying population distribution!\n\n\nAnother convenient result is that the distribution of means will have a “normal” shape regardless of the underlying population distribution. This is true in remarkably many situations.\nAgain, this means that we may anticipate some characteristics of a distribution of samples"
  },
  {
    "objectID": "08-sampling-populations.html#the-distribution-of-samples-will-have-a-normal-shape-irrespective-of-the-underlying-population-distribution-1",
    "href": "08-sampling-populations.html#the-distribution-of-samples-will-have-a-normal-shape-irrespective-of-the-underlying-population-distribution-1",
    "title": "Estimating a sampling distribution",
    "section": "The distribution of samples will have a “normal” shape irrespective of the underlying population distribution!",
    "text": "The distribution of samples will have a “normal” shape irrespective of the underlying population distribution!"
  },
  {
    "objectID": "08-sampling-populations.html#the-normal-distribution",
    "href": "08-sampling-populations.html#the-normal-distribution",
    "title": "Estimating a sampling distribution",
    "section": "The Normal Distribution",
    "text": "The Normal Distribution\n\n\nThe shape of the distributions of samples we saw previously was Normal, the Normal or Gaussian distribution has some characteristics that are convenient for us. We can quantify the area under the curve in different segments of the distribution, usually using a computer program.\nThis is a standardized normal distribution.\nThe distribution is determined by a mean and standard deviation. One SD up from the mean captures about 34% of the area under the curve."
  },
  {
    "objectID": "08-sampling-populations.html#the-normal-distribution-1",
    "href": "08-sampling-populations.html#the-normal-distribution-1",
    "title": "Estimating a sampling distribution",
    "section": "The Normal distribution",
    "text": "The Normal distribution\n\n\nTwo SDs around the mean captures about 68% of the area, Four SDs captures about 95% and 3 SDs about 99%.\nFor calrity, the sum under the curve is 100%!"
  },
  {
    "objectID": "08-sampling-populations.html#sampling-distributions-1",
    "href": "08-sampling-populations.html#sampling-distributions-1",
    "title": "Estimating a sampling distribution",
    "section": "Sampling distributions",
    "text": "Sampling distributions\n\nThe variation (standard deviation) of a distribution of averages is affected by the sample size.\nThis variation can be estimated from samples and is known as the standard error.\nThe sample standard error is an estimate of the standard deviation of the sampling distribution!\n\n\\[SE = \\frac{s}{\\sqrt{n}}\\]\n\nAgain, a convenient result! We can estimate the variation of a distribution of samples drawn from a population using the sample standard error."
  },
  {
    "objectID": "08-sampling-populations.html#sampling-distributions-2",
    "href": "08-sampling-populations.html#sampling-distributions-2",
    "title": "Estimating a sampling distribution",
    "section": "Sampling distributions",
    "text": "Sampling distributions\n\n\nEven with small samples we are quite close. Larger samples will have less bias on average."
  },
  {
    "objectID": "08-sampling-populations.html#hypothesis-testing",
    "href": "08-sampling-populations.html#hypothesis-testing",
    "title": "Estimating a sampling distribution",
    "section": "Hypothesis testing",
    "text": "Hypothesis testing\n\n\nBased on the estimate of the sampling distribution we can device a test, to test if a value exists within specified range.\n95% of all values lies within \\(\\pm 1.96\\times \\sigma\\) from the mean in a normal distribution, this leaves us with an uncertainty of 5%.\nHowever, due to problems with proving a theory or hypothesis, we instead test against a null-hypothesis.\nThe null hypothesis \\(H_0\\) is constructed to contain scenarios not covered by the alternative hypothesis \\(H_A\\)"
  },
  {
    "objectID": "08-sampling-populations.html#hypothesis-tests---a-two-sample-scenario",
    "href": "08-sampling-populations.html#hypothesis-tests---a-two-sample-scenario",
    "title": "Estimating a sampling distribution",
    "section": "Hypothesis tests - a two sample scenario",
    "text": "Hypothesis tests - a two sample scenario\n\nThe null hypothesis is that the mean of group 1 is similar to group 2 \\(H_0: \\mu_1 - \\mu_2 = 0\\)\nTo reject this hypothesis, we need to find support for \\(\\mu_1 - \\mu_2 \\neq 0\\)\nWe want to do this with some specified error control, usually 5%. We accept that we will wrong in a specified number of cases.\nWe can calculate a 95% confidence interval of the difference"
  },
  {
    "objectID": "08-sampling-populations.html#a-95-confidence-interval-for-small-samples",
    "href": "08-sampling-populations.html#a-95-confidence-interval-for-small-samples",
    "title": "Estimating a sampling distribution",
    "section": "A 95% confidence interval for small samples",
    "text": "A 95% confidence interval for small samples\nUpper bound: \\[\\bar{x} + t_{1-\\alpha/2} \\times SE\\] Lower bound: \\[\\bar{x} - t_{1-\\alpha/2} \\times SE\\]\n\n\\(\\bar{x}\\) is the difference in means between groups.\nThe standard error (\\(SE\\)) estimates the standard deviation of the sampling distribution\n\\(t_{1-\\alpha/2}\\) represents the area under probability distribution curve containing 95% of all values.\nThe \\(t\\)-distribution is used instead of the normal distribution since it can capture deviations from the Normal distribution due to the sample size."
  },
  {
    "objectID": "08-sampling-populations.html#the-t-distribution",
    "href": "08-sampling-populations.html#the-t-distribution",
    "title": "Estimating a sampling distribution",
    "section": "The t-distribution",
    "text": "The t-distribution"
  },
  {
    "objectID": "08-sampling-populations.html#a-case-with-samples-from-two-groups",
    "href": "08-sampling-populations.html#a-case-with-samples-from-two-groups",
    "title": "Estimating a sampling distribution",
    "section": "A case with samples from two groups",
    "text": "A case with samples from two groups"
  },
  {
    "objectID": "08-sampling-populations.html#a-95-confidence-of-the-difference-in-means",
    "href": "08-sampling-populations.html#a-95-confidence-of-the-difference-in-means",
    "title": "Estimating a sampling distribution",
    "section": "A 95% confidence of the difference in means",
    "text": "A 95% confidence of the difference in means\n\nTwo groups are compared, the \\(H_0\\) is that there is no difference between the groups: \\(H_0: \\mu_1 = \\mu_2\\)\nThe difference between the groups are estimated to \\(\\mu_2 - \\mu_1 =\\) 0.97\nThe 95% confidence interval is \\(m_2 - m_1 \\pm t_{\\alpha/2} \\times SE(m_2 - m_1)\\) where the \\(SE(m_2 - m_1)\\) is the standard error of the difference."
  },
  {
    "objectID": "08-sampling-populations.html#a-95-confidence-of-the-difference-in-means-1",
    "href": "08-sampling-populations.html#a-95-confidence-of-the-difference-in-means-1",
    "title": "Estimating a sampling distribution",
    "section": "A 95% confidence of the difference in means",
    "text": "A 95% confidence of the difference in means"
  },
  {
    "objectID": "08-sampling-populations.html#summary",
    "href": "08-sampling-populations.html#summary",
    "title": "Estimating a sampling distribution",
    "section": "Summary",
    "text": "Summary\n\nWe can estimate population parameters using a random sample from the population\nThe calculated sample standard error is an estimate of the standard deviation of a sampling distribution\nUsing a probability density function like the \\(t\\)- or \\(z\\)-distribution, we can estimate a range a plausible values of a population parameter (e.g. mean).\nWe can test if a estimated interval contains the null hypothesis, if not we can reject \\(H_0\\)."
  },
  {
    "objectID": "09-statistical-power.html#null-hypothesis-significance-testing-nhst",
    "href": "09-statistical-power.html#null-hypothesis-significance-testing-nhst",
    "title": "Statistical Power and Significance testing",
    "section": "Null hypothesis significance testing (NHST)",
    "text": "Null hypothesis significance testing (NHST)\n\nChoose a null-hypothesis, e.g. there is no differences between groups \\(H_0:\\mu_1 = \\mu_2\\), and a alternative hypothesis e.g. \\(H_1:\\mu_1 - \\mu_2 \\neq 0\\)\nSpecify a significance level, usually 5% (or \\(\\alpha=0.05\\)).\nPerform an appropriate test, in the case of differences between means, a t-test and calculate the \\(p\\)-value\nIf the \\(p\\)-value is less than the stated \\(\\alpha\\)-level we declare the result as statistically significant and reject \\(H_0\\).\n\n\n\nNHST is probably the most common way of making decisions about effects within quantitative sciences:\nNHST can be used to assess if e.g. groups are different or regression parameters are different than zero.\nNHST can be performed using the following steps:"
  },
  {
    "objectID": "09-statistical-power.html#nhst-is-a-special-flavour-of-hypothesis-testing",
    "href": "09-statistical-power.html#nhst-is-a-special-flavour-of-hypothesis-testing",
    "title": "Statistical Power and Significance testing",
    "section": "NHST is a special flavour of hypothesis testing",
    "text": "NHST is a special flavour of hypothesis testing\n\nTwo competing views on hypothesis testing were originally presented by Ronald A. Fisher on the one hand and Jerzy Neyman and Egon Pearson on the other hand."
  },
  {
    "objectID": "09-statistical-power.html#nhst-is-a-special-flavour-of-hypothesis-testing-1",
    "href": "09-statistical-power.html#nhst-is-a-special-flavour-of-hypothesis-testing-1",
    "title": "Statistical Power and Significance testing",
    "section": "NHST is a special flavour of hypothesis testing",
    "text": "NHST is a special flavour of hypothesis testing\n\n\n\n\n\n\n\nFisher\nNeyman-Pearson\n\n\n\n\n1. State \\(H_0\\)\n1. State \\(H_0\\) and \\(H_1\\)\n\n\n2. Specify test statistic\n2. Specify \\(\\alpha\\) (e.g. 5%) and \\(\\beta\\)\n\n\n3. Collect data, calculate test statistic and \\(p\\)-value\n3. Specify test statistics and critical value\n\n\n4. Reject \\(H_0\\) if \\(p\\) is small\n4. Collect data, calculate test statistic, determine \\(p\\)\n\n\n\n5. Reject \\(H_0\\) in favour of \\(H_1\\) if \\(p &lt; \\alpha\\)\n\n\n\n(Kline 2013)"
  },
  {
    "objectID": "09-statistical-power.html#statistical-power-1-beta",
    "href": "09-statistical-power.html#statistical-power-1-beta",
    "title": "Statistical Power and Significance testing",
    "section": "Statistical power (\\(1-\\beta\\))!",
    "text": "Statistical power (\\(1-\\beta\\))!\n\nNeyman and Pearson extended Fishers hypothesis testing procedure with the concept of power.\nAn alternative hypothesis can be stated for a specific value of e.g. a difference \\(H_1: \\mu_1-\\mu_2 = 5\\)\nUsing this alternative hypothesis we can calculate the statistical power: The rate of rejecting \\(H_0\\) if the alternative hypothesis is true.\nThe rate at which we fail to reject \\(H_0\\) if \\(H_1\\) is true is the Type 2 error rate (\\(\\beta\\)).\nStatistical power is therefore: \\(1-\\beta\\)."
  },
  {
    "objectID": "09-statistical-power.html#errors-in-nhst",
    "href": "09-statistical-power.html#errors-in-nhst",
    "title": "Statistical Power and Significance testing",
    "section": "Errors in NHST",
    "text": "Errors in NHST\n\nThere are two scenarios where we make mistakes, by rejecting \\(H_0\\) when it is actually true and not rejecting \\(H_0\\) when it is false.\n\n\n\n\n\n\n\n\n\nState of the world\n\n\n\n\n\n\nDecision\n\n\n\\(H_0\\) true\n\n\n\\(H_0\\) false\n\n\n\n\nAccept \\(H_0\\)\n\n\n\n\nType II error\n\n\n\n\nReject \\(H_0\\)\n\n\nType I error"
  },
  {
    "objectID": "09-statistical-power.html#error-rates-in-nhst",
    "href": "09-statistical-power.html#error-rates-in-nhst",
    "title": "Statistical Power and Significance testing",
    "section": "Error rates in NHST",
    "text": "Error rates in NHST\n\nWe usually specify the level of Type I errors to 5%\nAnother convention is to specify the power to 80%, this means that the risk of failing to reject \\(H_0\\) when \\(H_0\\) is false is 20%.\nThese levels are chosen by tradition(!), but a well designed study is planned using well thought through Type I and II error rates.\nIn the case of \\(\\alpha = 0.05\\) and \\(\\beta=0.2\\), Cohen (2013) pointed out that this can be thought of as Type I errors being a mistake four times more serious than Type II errors. (\\(\\frac{0.20}{0.05} = 4\\))\nRates could be adjusted to represent the relative seriousness of respective errors."
  },
  {
    "objectID": "09-statistical-power.html#the-p-value-again",
    "href": "09-statistical-power.html#the-p-value-again",
    "title": "Statistical Power and Significance testing",
    "section": "The \\(p\\)-value (again!)",
    "text": "The \\(p\\)-value (again!)\n\n\nThe \\(p\\)-value is the probability of obtaining a value of a test statistic (t) as extreme as the one obtained or more extreme under the condition that the null-hypothesis is true (sometimes written as \\(p(t|H_0)\\))\nWe assume that the null is true and we calculate how often a result such as the one obtained, or even more extreme, would occur as a result of chance.\nThe \\(\\alpha\\)-level is the Type I error rate, the probability of rejecting \\(H_0\\) when it is actually true.\n\n\n\n\nUsing \\(\\alpha = 0.05\\) we simply declare significant when \\(p&lt;0.05\\) (and accept that we will be wrong in 5% of an infinite number of studies), this is the Neyman-Person approach,"
  },
  {
    "objectID": "09-statistical-power.html#interpreting-p-values",
    "href": "09-statistical-power.html#interpreting-p-values",
    "title": "Statistical Power and Significance testing",
    "section": "Interpreting \\(p\\)-values",
    "text": "Interpreting \\(p\\)-values\n\nThere are (commonly in scientific practice) two distinct ways of looking at the \\(p\\)-value, one where the \\(p\\)-value is a pre-specified threshold for decision (Neyman-Pearson), and one where the \\(p\\)-value is thought of as a measure of strength of evidence against the null-hypothesis (Fisher)."
  },
  {
    "objectID": "09-statistical-power.html#interpreting-p-values-1",
    "href": "09-statistical-power.html#interpreting-p-values-1",
    "title": "Statistical Power and Significance testing",
    "section": "Interpreting \\(p\\)-values",
    "text": "Interpreting \\(p\\)-values\n\n\nIt is common practice to combine the two approaches in analysis of scientific experiments. Examples:\n\n“There was not a significant difference between groups but the p-values suggested a trend towards …”\n“The difference between group A and B was significant, but the difference between A and C was highly significant”\n\nAccording to the original frameworks, the mix (Fisher combined with Neyman-Pearson) may lead to abuse of NHST"
  },
  {
    "objectID": "09-statistical-power.html#interpreting-p-values-2",
    "href": "09-statistical-power.html#interpreting-p-values-2",
    "title": "Statistical Power and Significance testing",
    "section": "Interpreting \\(p\\)-values",
    "text": "Interpreting \\(p\\)-values\n\n\nNeyman and Pearson thought about \\(\\alpha\\) and \\(\\beta\\) as probabilities attached to the testing procedure.\n\\(\\alpha\\) and \\(\\beta\\) should be decided before the experiment and guide the researcher in making decisions.\nControlling \\(\\alpha\\) and \\(\\beta\\) is about controlling error rates!\nFisher believed that the \\(p\\)-value could serve as a statement about null-hypothesis given the sample…\n\n\n(Dienes 2008)"
  },
  {
    "objectID": "09-statistical-power.html#the-alpha-error-and-statistical-power-are-related",
    "href": "09-statistical-power.html#the-alpha-error-and-statistical-power-are-related",
    "title": "Statistical Power and Significance testing",
    "section": "The \\(\\alpha\\)-error and statistical power are related",
    "text": "The \\(\\alpha\\)-error and statistical power are related\n\n\nThis means that there is always a trade-off between power an type-I errors! Unless you can have large n!\nWhat does a power of 0.5 mean?"
  },
  {
    "objectID": "09-statistical-power.html#error-rates-in-nhst-an-example",
    "href": "09-statistical-power.html#error-rates-in-nhst-an-example",
    "title": "Statistical Power and Significance testing",
    "section": "Error rates in NHST, an example",
    "text": "Error rates in NHST, an example\n\nIf a study tries to determine if a novel treatment with no known side-effects should be implemented, failure to detect a difference compared to placebo when there is a difference (Type II error) would be more serious than to detect a difference that is not true (Type I error).\n\n\n\nIn this case error rates could be adjusted to reflect this, decrease possibility Type II errors by increasing the possibility of Type I errors."
  },
  {
    "objectID": "09-statistical-power.html#power-analysis-in-nhst",
    "href": "09-statistical-power.html#power-analysis-in-nhst",
    "title": "Statistical Power and Significance testing",
    "section": "Power analysis in NHST",
    "text": "Power analysis in NHST\n\n\nThis is a question of cost as more participants means more work\nIt is a question of ethics as more participants means that more people are subjected to risk/discomfort.\nWe aim to recruit as many participants as is necessary to answer our question.\nWe state our \\(H_0\\) and \\(H_1\\) (according to the Neyman-Pearson tradition).\nWhen we have specified \\(H_1\\) we can perform power analysis and sample size estimation.\n\n\n\n\nThe \\(H_1\\) has a special function, this can be seen as the smallest meaningful difference between conditions under study, the difference we want to be able to detect."
  },
  {
    "objectID": "09-statistical-power.html#power-analysis-an-example",
    "href": "09-statistical-power.html#power-analysis-an-example",
    "title": "Statistical Power and Significance testing",
    "section": "Power analysis, an example",
    "text": "Power analysis, an example\n\n\nA 1 kg difference in lean mass increases is considered a meaningful difference after 12 weeks of training.\nThe standard deviation from previous studies is used to estimate the expected variation in responses to 12 weeks of resistance training (\\(\\sigma = 2.5\\)).\n\nTo calculate the required sample size we first must calculate a standardized effect size, also known as Cohen’s \\(d\\).\nWe can standardize our “effect size” of 1 kg by dividing by the SD \\(d = \\frac{1}{2.5}= 0.4\\)\n\n\n\n\nWe want to compare the muscle mass gains as a result of two resistance training protocols."
  },
  {
    "objectID": "09-statistical-power.html#effect-sizes",
    "href": "09-statistical-power.html#effect-sizes",
    "title": "Statistical Power and Significance testing",
    "section": "Effect sizes",
    "text": "Effect sizes\n\nThe effect size is the primary aim of an experiment, we wish to know the difference, correlation, regression coefficient, percentage change…\nThe effect size can be standardized (e.g. divided by the standard deviation or calculated as e.g. a correlation)."
  },
  {
    "objectID": "09-statistical-power.html#power-analysis-an-example-cont.",
    "href": "09-statistical-power.html#power-analysis-an-example-cont.",
    "title": "Statistical Power and Significance testing",
    "section": "Power analysis, an example cont.",
    "text": "Power analysis, an example cont.\n\nLet’s say that the Type I error is four times more serious than the Type II error, and that we would accept to be wrong in rejecting \\(H_0\\) at a rate of 5%.\n\n\\[\\alpha=0.05,~\\beta=0.2,~d = 0.4\\]\n\nGiven these specifics we would require 100 in each group to be able to show a meaningful difference with the power set to 80%.\n\n\n\nWe must specify \\(\\alpha\\) and \\(1-\\beta\\) to calculate the required sample size!\nThis is a big study what if we examine the smallest difference we can detect using a set sample size"
  },
  {
    "objectID": "09-statistical-power.html#mean-difference-between-groups-vs.-number-of-participants-per-group",
    "href": "09-statistical-power.html#mean-difference-between-groups-vs.-number-of-participants-per-group",
    "title": "Statistical Power and Significance testing",
    "section": "Mean difference between groups vs. number of participants per group",
    "text": "Mean difference between groups vs. number of participants per group"
  },
  {
    "objectID": "09-statistical-power.html#power-analysis",
    "href": "09-statistical-power.html#power-analysis",
    "title": "Statistical Power and Significance testing",
    "section": "Power analysis",
    "text": "Power analysis\nStatistical power is influenced by:\n\n\nThe \\(\\alpha\\) level\nThe direction of the hypothesis (negative, positive or both ways different from \\(H_0\\))\nExperimental design (e.g. within- or between-participants)\nThe statistical test\nReliability of test scores"
  },
  {
    "objectID": "09-statistical-power.html#critique-of-nhst",
    "href": "09-statistical-power.html#critique-of-nhst",
    "title": "Statistical Power and Significance testing",
    "section": "Critique of NHST",
    "text": "Critique of NHST\n\nNHST with \\(p\\)-values tend to create an “either-or” situation, gives no answer about the size of an effect\nTest statistics are related to sample size, small effects can be detected using big sample sizes\nBuilt in to the NHST framework is the acceptance of a proportion of tests being false positive (\\(\\alpha\\)), the risk of getting false positives increases with the number of tests."
  },
  {
    "objectID": "09-statistical-power.html#nhst-and-magnitude-of-an-effect",
    "href": "09-statistical-power.html#nhst-and-magnitude-of-an-effect",
    "title": "Statistical Power and Significance testing",
    "section": "NHST and magnitude of an effect",
    "text": "NHST and magnitude of an effect\n\n“The training group gained 3 kg in muscle mass from pre- to post-training (p&lt;0.05)”\n\n\nSome scientists wants to use the p-value as a signal of importance…"
  },
  {
    "objectID": "09-statistical-power.html#statistical-significance-and-clinical-significance",
    "href": "09-statistical-power.html#statistical-significance-and-clinical-significance",
    "title": "Statistical Power and Significance testing",
    "section": "Statistical significance and clinical significance",
    "text": "Statistical significance and clinical significance\nLarge sample sizes can make small effect sizes statistically significant. Example, (Lee 2010):\n\nObjective: To examine the association of different amounts of physical activity with long-term weight changes among women consuming a usual diet.\nDesign: Prospective cohort study, following 34,079 healthy, US women (mean age, 54.2 years) from 1992–2007. At baseline, 36-, 72-, 96-, 120-, 144- and 156-months’ follow-up, women reported their physical activity and body weight."
  },
  {
    "objectID": "09-statistical-power.html#statistical-significance-and-clinical-significance-1",
    "href": "09-statistical-power.html#statistical-significance-and-clinical-significance-1",
    "title": "Statistical Power and Significance testing",
    "section": "Statistical significance and clinical significance",
    "text": "Statistical significance and clinical significance\n\nResults: Women gained a mean of 2.6 kg throughout the study. In multivariate analysis, compared with women expending \\(\\geq\\) 21 MET-hr/week, those expending 7.5-&lt;21 and &lt;7.5 MET-hr/week gained 0.11 kg (SD=0.04; P=0.003) and 0.12 kg (SD=0.04; P=0.002), respectively, over a mean interval of 3 years.\n\n(Lee 2010)"
  },
  {
    "objectID": "09-statistical-power.html#results",
    "href": "09-statistical-power.html#results",
    "title": "Statistical Power and Significance testing",
    "section": "Results",
    "text": "Results\n\n(Lee 2010)"
  },
  {
    "objectID": "09-statistical-power.html#making-the-wrong-decision-5-of-the-time",
    "href": "09-statistical-power.html#making-the-wrong-decision-5-of-the-time",
    "title": "Statistical Power and Significance testing",
    "section": "Making the wrong decision 5% of the time",
    "text": "Making the wrong decision 5% of the time\n\nGiven that NHST accepts mistakes at a rate of \\(\\alpha\\), every \\(\\frac{1}{\\alpha}=20^{th}\\) test result will be false!\nThe Neyman-Pearson approach is to only do NHST with an pre-specified \\(\\alpha\\)-level\nOne must also avoid making up hypotheses after the test.\nIf you do multiple tests, family-wise corrections can be made, e.g. the Bonferroni correction: \\(\\alpha_{Bonferroni}=\\frac{\\alpha}{n~tests}\\)\nFor statistical significance to be reached, the \\(\\alpha_{Bonferroni}\\) threshold must be reached."
  },
  {
    "objectID": "09-statistical-power.html#what-can-the-corrected-p-value-account-for",
    "href": "09-statistical-power.html#what-can-the-corrected-p-value-account-for",
    "title": "Statistical Power and Significance testing",
    "section": "What can the corrected \\(p\\)-value account for?",
    "text": "What can the corrected \\(p\\)-value account for?\n\n\nA statistical hypothesis test using the Neyman-Pearson approach is about error-control.\nA single test has specified errors, but these are affected by e.g. sequential testing, sneak-peaks on the data, issues with randomization and study designs…\nA large proportion of tests will not be “severe enough” to reject \\(H_0\\)\nWe are not always aware of when we adjust \\(\\alpha\\) the wrong way\n\n\n(Mayo 2018; Dienes 2008)\n\nThis is a note on the error control and severe testing proposed by Mayo."
  },
  {
    "objectID": "09-statistical-power.html#sequential-testing-will-lead-to-significant-results-eventually",
    "href": "09-statistical-power.html#sequential-testing-will-lead-to-significant-results-eventually",
    "title": "Statistical Power and Significance testing",
    "section": "Sequential testing will lead to significant results… eventually",
    "text": "Sequential testing will lead to significant results… eventually\n\nAlbers (2019)"
  },
  {
    "objectID": "09-statistical-power.html#the-philosophy-of-statistics-in-practice-is-a-mix",
    "href": "09-statistical-power.html#the-philosophy-of-statistics-in-practice-is-a-mix",
    "title": "Statistical Power and Significance testing",
    "section": "The philosophy of statistics, in practice, is a mix!",
    "text": "The philosophy of statistics, in practice, is a mix!\nJournal of Physiology: For a given conclusion to be assessed, the exact p-values must be stated to three significant figures even when ‘no statistical significance’ is being reported. These should be stated in the main text, figures and their legends and tables. The only exception to this is if p is less than 0.0001, in which case ‘&lt;’ is permitted. Trend statements are not permitted (i.e. ‘x increased, but was not significant’). Where there are many comparisons, a table of p values may be appropriate."
  },
  {
    "objectID": "09-statistical-power.html#what-does-the-p-value-mean",
    "href": "09-statistical-power.html#what-does-the-p-value-mean",
    "title": "Statistical Power and Significance testing",
    "section": "What does the p-value mean?",
    "text": "What does the p-value mean?\nAll groups regained weight after randomization by a mean of 5.5 kg in the self-directed, 5.2 kg in the interactive technology–based, and 4.0 kg in the personal-contact group… Those in the personal-contact group regained a mean of 1.2 kg less than those in the interactive technology–based group (95% CI, 2.1-0.3 kg; P=.008)."
  },
  {
    "objectID": "09-statistical-power.html#what-does-the-p-value-mean-svetkey-at-al",
    "href": "09-statistical-power.html#what-does-the-p-value-mean-svetkey-at-al",
    "title": "Statistical Power and Significance testing",
    "section": "What does the p-value mean? Svetkey at al…",
    "text": "What does the p-value mean? Svetkey at al…\n\n\n…have absolutely disproved the null hypothesis (that there is no difference between the population means).\n… have found the probability of the null hypothesis being true.\n… have absolutely proved their experimental hypothesis (that there is a difference between the population means).\n\n\nQuestions adopted from (Dienes 2008)."
  },
  {
    "objectID": "09-statistical-power.html#what-does-the-p-value-mean-svetkey-at-al-1",
    "href": "09-statistical-power.html#what-does-the-p-value-mean-svetkey-at-al-1",
    "title": "Statistical Power and Significance testing",
    "section": "What does the p-value mean? Svetkey at al…",
    "text": "What does the p-value mean? Svetkey at al…\n\n\n… can deduce the probability of the experimental hypothesis being true.\n… know the probability that you are making the wrong decision, if you decided to reject the null hypothesis.\n… have a reliable experimental finding in the sense that if, hypothetically, the experiment were repeated a great number of times, you would obtain a significant result on 95 % of occasions.\n\n\nQuestions adopted from (Dienes 2008)."
  },
  {
    "objectID": "09-statistical-power.html#a-complement-or-alternative-to-nhst-estimation",
    "href": "09-statistical-power.html#a-complement-or-alternative-to-nhst-estimation",
    "title": "Statistical Power and Significance testing",
    "section": "A complement or alternative to NHST: Estimation",
    "text": "A complement or alternative to NHST: Estimation\n\nInstead of testing against a null-hypothesis, estimation aims at finding a point estimate of the parameter of interest\nSecondly we want to find an interval estimate of the parameter\nThis can be done using confidence intervals.\nConfidence intervals provides an point-estimate together with a range of plausible values of the population parameter."
  },
  {
    "objectID": "09-statistical-power.html#estimation-an-example",
    "href": "09-statistical-power.html#estimation-an-example",
    "title": "Statistical Power and Significance testing",
    "section": "Estimation, an example",
    "text": "Estimation, an example\n\n\nWhat conclusions can be drawn from the two studies (using NHST vs. estimation)?\n\n(Cumming 2012)"
  },
  {
    "objectID": "09-statistical-power.html#estimation",
    "href": "09-statistical-power.html#estimation",
    "title": "Statistical Power and Significance testing",
    "section": "Estimation",
    "text": "Estimation\n\nIn addition to giving a interval representing the precision of the estimate, the confidence interval can be used to assess the clinical importance of a study.\nAre values inside the confidence interval large (or small) enough to care about in a clinical sense (e.g. weight gain study)"
  },
  {
    "objectID": "09-statistical-power.html#estimation-using-confidence-intervals-still-has-the-draw-back-of-nhst",
    "href": "09-statistical-power.html#estimation-using-confidence-intervals-still-has-the-draw-back-of-nhst",
    "title": "Statistical Power and Significance testing",
    "section": "Estimation using confidence intervals still has the draw-back of NHST",
    "text": "Estimation using confidence intervals still has the draw-back of NHST"
  },
  {
    "objectID": "09-statistical-power.html#alternatives-to-null-hypothesis-testing",
    "href": "09-statistical-power.html#alternatives-to-null-hypothesis-testing",
    "title": "Statistical Power and Significance testing",
    "section": "Alternatives to Null-hypothesis testing",
    "text": "Alternatives to Null-hypothesis testing\n\n\nIf you are interested in quantifying the probability of obtaining the population parameter, given your prior understanding → Bayesian statistics!\nIf you want to quantify the relative evidence in favour of a hypothesis over another based on your data → Likelihood inference!"
  },
  {
    "objectID": "09-statistical-power.html#references",
    "href": "09-statistical-power.html#references",
    "title": "Statistical Power and Significance testing",
    "section": "References",
    "text": "References\n\n\n\n\n\n\nAlbers, Casper. 2019. “The Problem with Unadjusted Multiple and Sequential Statistical Testing.” Nature Communications 10 (1): 1921. https://doi.org/10.1038/s41467-019-09941-0.\n\n\nCohen, Jacob. 2013. Statistical Power Analysis for the Behavioral Sciences. 0th ed. Routledge. https://doi.org/10.4324/9780203771587.\n\n\nCumming, Geoff. 2012. Understanding the New Statistics : Effect Sizes, Confidence Intervals, and Meta-Analysis. Multivariate Applications Series. New York: Routledge.\n\n\nDienes, Zoltan. 2008. Understanding Psychology as a Science: An Introduction to Scientific and Statistical Inference. New York: Palgrave Macmillan.\n\n\nKline, Rex B. 2013. Beyond Significance Testing: Statistics Reform in the Behavioral Sciences, 2nd Ed. Beyond Significance Testing: Statistics Reform in the Behavioral Sciences, 2nd Ed. Washington, DC, US: American Psychological Association. https://doi.org/10.1037/14136-000.\n\n\nLee, I-Min. 2010. “Physical Activity and Weight Gain Prevention.” JAMA 303 (12): 1173. https://doi.org/10.1001/jama.2010.312.\n\n\nMayo, Deborah G. 2018. Statistical Inference as Severe Testing : How to Get Beyond the Statistics Wars. Cambridge ; New York, NY: Cambridge University Press."
  },
  {
    "objectID": "devel/xx-study-design.html#quarto",
    "href": "devel/xx-study-design.html#quarto",
    "title": "Designing scientific studies",
    "section": "Quarto",
    "text": "Quarto\nQuarto enables you to weave together content and executable code into a finished presentation. To learn more about Quarto presentations see https://quarto.org/docs/presentations/."
  },
  {
    "objectID": "devel/xx-study-design.html#bullets",
    "href": "devel/xx-study-design.html#bullets",
    "title": "Designing scientific studies",
    "section": "Bullets",
    "text": "Bullets\nWhen you click the Render button a document will be generated that includes:\n\nContent authored with markdown\nOutput from executable code"
  },
  {
    "objectID": "devel/xx-study-design.html#code",
    "href": "devel/xx-study-design.html#code",
    "title": "Designing scientific studies",
    "section": "Code",
    "text": "Code\nWhen you click the Render button a presentation will be generated that includes both content and the output of embedded code. You can embed code like this:\n\n\n[1] 2"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Quantitative methods and statistics (In Sport and Exercise Science) - Lectures",
    "section": "",
    "text": "Lecture\nNotes\n\n\n\n\nIntroduction to data science\n\n\n\nIntroduction to data visualization\nHomework, possible solutions\n\n\nIntroduction to data wrangling\nHomework, possible solution\n\n\nWriting reports in quarto\n\n\n\nAssociations, correlation and regression\n\n\n\nStatistical inference\n\n\n\nSamples and populations\n\n\n\nStatistical power"
  }
]